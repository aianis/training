{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17598fe5",
   "metadata": {},
   "source": [
    "# TCN Training on Google Colab (GPU) - IMPROVED VERSION\n",
    "\n",
    "**ðŸ”§ This version includes critical fixes for training stability:**\n",
    "- âœ… Per-target normalization (prevents scale imbalance)\n",
    "- âœ… Stronger gradient clipping (5.0 instead of 1.0)\n",
    "- âœ… Lower learning rate with warmup (5e-4 with 5-epoch warmup)\n",
    "- âœ… Gradient monitoring and NaN detection\n",
    "- âœ… Prediction clipping to prevent explosions\n",
    "- âœ… Better hyperparameters (smaller batches, higher dropout)\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "1. **Upload to Google Drive:**\n",
    "   - Upload your `data/processed/robot_data/` folder to Google Drive under:\n",
    "     `My Drive/Internship/data/processed/robot_data/`\n",
    "   - Upload the `robot_data_pipeline/` folder to:\n",
    "     `My Drive/Internship/robot_data_pipeline/`\n",
    "\n",
    "2. **Enable GPU:**\n",
    "   - Go to `Runtime` â†’ `Change runtime type` â†’ Select **T4 GPU**\n",
    "\n",
    "3. **Run all cells** (`Runtime` â†’ `Run all`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5f793b",
   "metadata": {},
   "source": [
    "## 0. Mount Google Drive & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54bad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceacf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch pandas pyarrow scikit-learn scipy tqdm xgboost -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "repo_sync_md",
   "metadata": {},
   "source": [
    "## 0.1 Sync Notebook from GitHub\n",
    "\n",
    "This pulls latest updates from your repo at runtime.\n",
    "\n",
    "For private repos, add a Colab Secret named `GITHUB_TOKEN` (or `GH_TOKEN` / `GITHUB_PAT`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "repo_sync_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse, urlunparse\n",
    "\n",
    "REPO_URL = \"https://github.com/aianis/training.git\"\n",
    "REPO_BRANCH = \"main\"\n",
    "REPO_DIR = Path(\"/content/training\")\n",
    "NOTEBOOK_NAME = \"colab_train_tcn_improved.ipynb\"\n",
    "AUTO_SYNC_REPO = True\n",
    "TOKEN_KEYS = (\"GITHUB_TOKEN\", \"GH_TOKEN\", \"GITHUB_PAT\")\n",
    "\n",
    "def _redact(text, secrets):\n",
    "    out = text\n",
    "    for secret in secrets:\n",
    "        if secret:\n",
    "            out = out.replace(secret, \"***\")\n",
    "    return out\n",
    "\n",
    "def run_cmd(cmd, cwd=None, secrets=None):\n",
    "    secrets = secrets or []\n",
    "    printable = _redact(\" \".join(cmd), secrets)\n",
    "    print(\"+\", printable)\n",
    "    result = subprocess.run(cmd, cwd=str(cwd) if cwd else None, text=True, capture_output=True)\n",
    "    if result.stdout:\n",
    "        print(_redact(result.stdout.strip(), secrets))\n",
    "    if result.returncode != 0:\n",
    "        if result.stderr:\n",
    "            print(_redact(result.stderr.strip(), secrets))\n",
    "        raise RuntimeError(f\"Command failed ({result.returncode}): {printable}\")\n",
    "    return result\n",
    "\n",
    "def get_github_token():\n",
    "    # 1) Colab secrets\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        for key in TOKEN_KEYS:\n",
    "            value = userdata.get(key)\n",
    "            if value:\n",
    "                return value.strip(), f\"colab-secret:{key}\"\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 2) Environment variables\n",
    "    for key in TOKEN_KEYS:\n",
    "        value = os.getenv(key)\n",
    "        if value:\n",
    "            return value.strip(), f\"env:{key}\"\n",
    "\n",
    "    return \"\", \"none\"\n",
    "\n",
    "def build_auth_url(repo_url, token):\n",
    "    if not token:\n",
    "        return repo_url\n",
    "    parsed = urlparse(repo_url)\n",
    "    netloc = f\"x-access-token:{token}@{parsed.netloc}\"\n",
    "    return urlunparse((parsed.scheme, netloc, parsed.path, parsed.params, parsed.query, parsed.fragment))\n",
    "\n",
    "if AUTO_SYNC_REPO:\n",
    "    token, token_source = get_github_token()\n",
    "    auth_url = build_auth_url(REPO_URL, token)\n",
    "    print(f\"Token source: {token_source}\")\n",
    "\n",
    "    if (REPO_DIR / \".git\").exists():\n",
    "        run_cmd([\"git\", \"fetch\", auth_url, REPO_BRANCH], cwd=REPO_DIR, secrets=[token])\n",
    "        run_cmd([\"git\", \"checkout\", REPO_BRANCH], cwd=REPO_DIR)\n",
    "        run_cmd([\"git\", \"pull\", \"--ff-only\", auth_url, REPO_BRANCH], cwd=REPO_DIR, secrets=[token])\n",
    "    else:\n",
    "        run_cmd([\"git\", \"clone\", \"--branch\", REPO_BRANCH, \"--single-branch\", auth_url, str(REPO_DIR)], secrets=[token])\n",
    "\n",
    "    nb_path = REPO_DIR / NOTEBOOK_NAME\n",
    "    if nb_path.exists():\n",
    "        print(f\"Synced notebook: {nb_path}\")\n",
    "    else:\n",
    "        print(f\"WARNING: {NOTEBOOK_NAME} not found in {REPO_DIR}\")\n",
    "else:\n",
    "    print(\"Repository auto-sync disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run_order_md",
   "metadata": {},
   "source": [
    "## 0.2 Final Colab Run-Order Checklist\n",
    "\n",
    "Run the notebook in this exact order to avoid stale state and invalid comparisons:\n",
    "\n",
    "1. **0. Mount + dependencies**\n",
    "2. **0.1 Sync Notebook from GitHub**\n",
    "3. **0.2 Run-Order Checklist** (this section)\n",
    "4. **1 ? 3 Data/feature/dataset setup**\n",
    "5. **Model + training + evaluation cells**\n",
    "6. **ExtraTrees fairness/evidence cells**\n",
    "7. **Saving results**\n",
    "8. **0.3 Push Notebook Updates to GitHub** (final step)\n",
    "\n",
    "Hard rules:\n",
    "- Do not skip the contract checks (window alignment + leakage checks).\n",
    "- Keep splits/strides fixed across deep models and ET baselines for parity.\n",
    "- Push only after benchmark JSON and artifacts are written successfully.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_order_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "print('=' * 70)\n",
    "print('RUN-ORDER CHECK')\n",
    "print('=' * 70)\n",
    "\n",
    "checks = []\n",
    "checks.append(('repo_sync_config_present', 'REPO_DIR' in globals() and 'NOTEBOOK_NAME' in globals()))\n",
    "checks.append(('config_present', 'config' in globals()))\n",
    "checks.append(('feature_engineer_present', 'fe' in globals()))\n",
    "checks.append(('dataset_loaders_present', all(k in globals() for k in ['train_loader', 'val_loader', 'test_loader'])))\n",
    "checks.append(('model_factories_present', 'model_builders' in globals()))\n",
    "checks.append(('training_results_present', 'deep_training_results' in globals()))\n",
    "checks.append(('deep_eval_present', 'deep_test_results' in globals()))\n",
    "checks.append(('xgb_results_present', 'et_benchmark_results' in globals()))\n",
    "checks.append(('hybrid_results_present', (not globals().get('config', None)) or (not getattr(config, 'run_physics_hybrid', False)) or ('hybrid_results' in globals())))\n",
    "checks.append(('save_results_ready', 'config' in globals() and hasattr(config, 'artifacts_dir')))\n",
    "\n",
    "for name, ok in checks:\n",
    "    print(f\"{('OK' if ok else 'MISSING'):>8s} | {name}\")\n",
    "\n",
    "missing = [name for name, ok in checks if not ok]\n",
    "if missing:\n",
    "    print('\\nAction: run preceding sections before pushing.')\n",
    "    print('Missing:', missing)\n",
    "else:\n",
    "    print('\\nAll major stages are present. Safe to run save + push.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "push_md",
   "metadata": {},
   "source": [
    "## 0.3 Push Notebook Updates to GitHub\n",
    "\n",
    "Use this only after training/evaluation/save cells complete.\n",
    "\n",
    "Required token setup (private repo):\n",
    "- Add one Colab Secret named `GITHUB_TOKEN` (or `GH_TOKEN` / `GITHUB_PAT`).\n",
    "- Token needs repo write access to `aianis/training`.\n",
    "\n",
    "This cell commits **only** `colab_train_tcn_improved.ipynb` in the synced repo and pushes to `main`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "push_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "PUSH_NOTEBOOK_UPDATES = False  # Set True to enable push\n",
    "PUSH_BRANCH = REPO_BRANCH if 'REPO_BRANCH' in globals() else 'main'\n",
    "\n",
    "# Update this if your active notebook lives outside /content/training\n",
    "SOURCE_NOTEBOOK = Path('/content/drive/MyDrive/Projects/torque_estimation_pipeline/02 Code and Scripts/colab_train_tcn_improved.ipynb')\n",
    "\n",
    "if not PUSH_NOTEBOOK_UPDATES:\n",
    "    print('Push disabled. Set PUSH_NOTEBOOK_UPDATES=True to push changes.')\n",
    "else:\n",
    "    if 'run_cmd' not in globals() or 'get_github_token' not in globals() or 'build_auth_url' not in globals():\n",
    "        raise RuntimeError('Run section 0.1 first so git helper functions are defined.')\n",
    "\n",
    "    repo_dir = Path(REPO_DIR)\n",
    "    repo_nb = repo_dir / NOTEBOOK_NAME\n",
    "\n",
    "    if not (repo_dir / '.git').exists():\n",
    "        raise RuntimeError(f'Repo not initialized at {repo_dir}. Run section 0.1 first.')\n",
    "\n",
    "    src = SOURCE_NOTEBOOK if SOURCE_NOTEBOOK.exists() else repo_nb\n",
    "    if not src.exists():\n",
    "        raise FileNotFoundError(f'Notebook source not found: {src}')\n",
    "\n",
    "    if src.resolve() != repo_nb.resolve():\n",
    "        shutil.copy2(src, repo_nb)\n",
    "        print(f'Copied notebook to repo: {repo_nb}')\n",
    "\n",
    "    # Ensure branch up-to-date\n",
    "    token, token_source = get_github_token()\n",
    "    if not token:\n",
    "        raise RuntimeError('No token found. Add a Colab Secret: GITHUB_TOKEN (or GH_TOKEN / GITHUB_PAT).')\n",
    "    auth_url = build_auth_url(REPO_URL, token)\n",
    "    print(f'Token source: {token_source}')\n",
    "\n",
    "    run_cmd(['git', 'fetch', auth_url, PUSH_BRANCH], cwd=repo_dir, secrets=[token])\n",
    "    run_cmd(['git', 'checkout', PUSH_BRANCH], cwd=repo_dir)\n",
    "    run_cmd(['git', 'pull', '--ff-only', auth_url, PUSH_BRANCH], cwd=repo_dir, secrets=[token])\n",
    "\n",
    "    # Configure identity if missing\n",
    "    try:\n",
    "        run_cmd(['git', 'config', 'user.email'], cwd=repo_dir)\n",
    "    except Exception:\n",
    "        run_cmd(['git', 'config', 'user.email', 'colab-bot@users.noreply.github.com'], cwd=repo_dir)\n",
    "    try:\n",
    "        run_cmd(['git', 'config', 'user.name'], cwd=repo_dir)\n",
    "    except Exception:\n",
    "        run_cmd(['git', 'config', 'user.name', 'colab-bot'], cwd=repo_dir)\n",
    "\n",
    "    run_cmd(['git', 'add', NOTEBOOK_NAME], cwd=repo_dir)\n",
    "\n",
    "    status = subprocess.run(['git', 'status', '--porcelain', NOTEBOOK_NAME], cwd=str(repo_dir), text=True, capture_output=True)\n",
    "    if not status.stdout.strip():\n",
    "        print('No notebook changes to commit.')\n",
    "    else:\n",
    "        stamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')\n",
    "        msg = f'Update notebook: {NOTEBOOK_NAME} ({stamp})'\n",
    "        run_cmd(['git', 'commit', '-m', msg], cwd=repo_dir)\n",
    "        run_cmd(['git', 'push', auth_url, PUSH_BRANCH], cwd=repo_dir, secrets=[token])\n",
    "        print('Push complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becf32dc",
   "metadata": {},
   "source": [
    "## 1. Configure Paths\n",
    "\n",
    "Adjust `DRIVE_ROOT` if you placed your files in a different Drive folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bda57e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURE THIS: path to your project folder on Google Drive\n",
    "# ============================================================\n",
    "DRIVE_ROOT = Path(\"/content/drive/MyDrive/Projects/torque_estimation_pipeline\")\n",
    "\n",
    "DATA_DIR       = DRIVE_ROOT / \"processed\" / \"robot_data\"\n",
    "PIPELINE_DIR   = DRIVE_ROOT / \"robot_data_pipeline\"\n",
    "ARTIFACTS_DIR  = DRIVE_ROOT / \"artifacts\" / \"tcn_improved_colab\"\n",
    "\n",
    "# Add pipeline to Python path\n",
    "sys.path.insert(0, str(DRIVE_ROOT))\n",
    "\n",
    "# Verify paths exist\n",
    "assert DATA_DIR.exists(), f\"Data directory not found: {DATA_DIR}\\nUpload data/processed/robot_data/ to Google Drive under the DRIVE_ROOT path.\"\n",
    "assert PIPELINE_DIR.exists(), f\"Pipeline not found: {PIPELINE_DIR}\\nUpload robot_data_pipeline/ to Google Drive under the DRIVE_ROOT path.\"\n",
    "\n",
    "parquet_files = list(DATA_DIR.rglob(\"*.parquet\"))\n",
    "print(f\"âœ“ Data directory found: {DATA_DIR}\")\n",
    "print(f\"  {len(parquet_files)} parquet files\")\n",
    "print(f\"âœ“ Pipeline found: {PIPELINE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f84839",
   "metadata": {},
   "source": [
    "## 2. Copy Data to Colab Local Disk (Faster I/O)\n",
    "\n",
    "Google Drive I/O is slow over FUSE mount. Copying to `/content/local_data/` speeds up training significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5cdfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, time\n",
    "\n",
    "LOCAL_DATA_DIR = Path(\"/content/local_data\")\n",
    "\n",
    "if not LOCAL_DATA_DIR.exists():\n",
    "    print(\"Copying data to Colab local disk (this may take a few minutes for 4 GB)...\")\n",
    "    t0 = time.time()\n",
    "    shutil.copytree(DATA_DIR, LOCAL_DATA_DIR)\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"âœ“ Copied in {elapsed:.0f}s\")\n",
    "else:\n",
    "    print(\"âœ“ Local data already exists\")\n",
    "\n",
    "local_files = list(LOCAL_DATA_DIR.rglob(\"*.parquet\"))\n",
    "print(f\"  {len(local_files)} parquet files on local disk\")\n",
    "\n",
    "# Use local path for training\n",
    "DATA_DIR_FAST = LOCAL_DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133dc08a",
   "metadata": {},
   "source": [
    "## 3. Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ca4edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import time\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import timedelta\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from robot_data_pipeline.feature_pipeline import FeatureEngineer, FeatureConfig\n",
    "from robot_data_pipeline.tcn_optimized import OptimizedTCN, count_parameters\n",
    "from robot_data_pipeline.trajectory_dataset import (\n",
    "    TrajectoryAwareDataset,\n",
    "    create_trajectory_datasets,\n",
    "    validate_no_boundary_crossing,\n",
    ")\n",
    "\n",
    "print(\"âœ“ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34656964",
   "metadata": {},
   "source": [
    "## 3.1. Per-Target Scaler - FIX #1\n",
    "\n",
    "**Critical Fix:** Scale each F/T target independently with `StandardScaler` for stable neural-network targets.\n",
    "\n",
    "Per-target `StandardScaler` keeps target magnitudes in a well-behaved Z-score range and avoids extreme value amplification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acd8ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerTargetScaler:\n",
    "    \"\"\"\n",
    "    StandardScaler (Z-score) is required for neural-network regression targets.\n",
    "    RobustScaler can amplify sparse-target outliers and destabilize gradients.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.scalers = {}\n",
    "        self.target_cols = []\n",
    "\n",
    "    def fit(self, X, target_cols):\n",
    "        self.target_cols = target_cols\n",
    "        for i, col in enumerate(target_cols):\n",
    "            scaler = StandardScaler()\n",
    "            if X.ndim == 1:\n",
    "                x_col = X.reshape(-1, 1)\n",
    "            else:\n",
    "                x_col = X[:, i:i+1]\n",
    "            scaler.fit(x_col)\n",
    "            self.scalers[col] = scaler\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "        result = np.zeros_like(X, dtype=np.float64)\n",
    "        for i, col in enumerate(self.target_cols):\n",
    "            result[:, i] = self.scalers[col].transform(X[:, i:i+1]).flatten()\n",
    "        return result\n",
    "\n",
    "    def inverse_transform(self, X):\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "        result = np.zeros_like(X, dtype=np.float64)\n",
    "        for i, col in enumerate(self.target_cols):\n",
    "            result[:, i] = self.scalers[col].inverse_transform(X[:, i:i+1]).flatten()\n",
    "        return result\n",
    "\n",
    "print(\"PerTargetScaler defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abf6fec",
   "metadata": {},
   "source": [
    "## 3.2. Gradient Monitoring - FIX #2\n",
    "\n",
    "**Critical Fix:** Detect gradient explosions early and skip problematic batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4773a8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gradients(model):\n",
    "    \"\"\"Check for NaN/Inf gradients and return max gradient norm.\n",
    "    \n",
    "    Returns:\n",
    "        (max_grad, has_nan, has_inf)\n",
    "    \"\"\"\n",
    "    max_grad = 0.0\n",
    "    has_nan = False\n",
    "    has_inf = False\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if param.grad is not None:\n",
    "            grad_max = param.grad.abs().max().item()\n",
    "            max_grad = max(max_grad, grad_max)\n",
    "            \n",
    "            if torch.isnan(param.grad).any():\n",
    "                has_nan = True\n",
    "            \n",
    "            if torch.isinf(param.grad).any():\n",
    "                has_inf = True\n",
    "    \n",
    "    return max_grad, has_nan, has_inf\n",
    "\n",
    "print(\"âœ“ Gradient monitoring defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525f5c25",
   "metadata": {},
   "source": [
    "## 3.3. Improved Training Configuration - FIX #3\n",
    "\n",
    "**Key Changes:**\n",
    "- Learning rate: 1e-3 â†’ **5e-4** (50% reduction)\n",
    "- Gradient clip: 1.0 â†’ **5.0** (5x stronger)\n",
    "- Batch size: 512 â†’ **256** (better generalization)\n",
    "- Dropout: 0.2 â†’ **0.3** (stronger regularization)\n",
    "- **NEW:** 5-epoch warmup period\n",
    "- Patience: 10 â†’ **15** (more stable early stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02827a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict\n",
    "import random\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    # Data\n",
    "    data_dir: Path = field(default_factory=lambda: DATA_DIR_FAST)\n",
    "    seq_len: int = 64\n",
    "    train_stride: int = 5\n",
    "    eval_stride: int = 2\n",
    "\n",
    "    # Models\n",
    "    model_names: Tuple[str, ...] = (\"tcn\", \"patchtst\", \"itransformer\")\n",
    "\n",
    "    # TCN params\n",
    "    channels: Tuple[int, ...] = (64, 128, 128, 64)\n",
    "    kernel_size: int = 3\n",
    "    dropout: float = 0.30\n",
    "\n",
    "    # PatchTST params\n",
    "    patch_len: int = 8\n",
    "    patch_stride: int = 4\n",
    "    patch_d_model: int = 128\n",
    "    patch_n_heads: int = 8\n",
    "    patch_n_layers: int = 4\n",
    "    patch_ffn_dim: int = 256\n",
    "    patch_dropout: float = 0.15\n",
    "    patch_use_revin: bool = True\n",
    "\n",
    "    # iTransformer params\n",
    "    itr_d_model: int = 128\n",
    "    itr_n_heads: int = 8\n",
    "    itr_n_layers: int = 4\n",
    "    itr_ffn_dim: int = 256\n",
    "    itr_dropout: float = 0.15\n",
    "    itr_use_revin: bool = True\n",
    "\n",
    "    # Training\n",
    "    batch_size: int = 256\n",
    "    epochs: int = 100\n",
    "    lr_tcn: float = 5e-4\n",
    "    lr_patchtst: float = 3e-4\n",
    "    lr_itransformer: float = 3e-4\n",
    "    warmup_epochs: int = 5\n",
    "    weight_decay: float = 1e-2\n",
    "    gradient_clip: float = 5.0\n",
    "\n",
    "    # Selection / early stopping\n",
    "    primary_metric: str = \"traj_nmae_iqr\"  # normalized trajectory-weighted MAE (train-IQR normalized)\n",
    "    secondary_metric: str = \"traj_r2_vw_orig\"\n",
    "    patience: int = 15\n",
    "    min_epochs_before_stop: int = 20\n",
    "    delta_primary_metric: float = 1e-3\n",
    "    delta_loss: float = 1e-4\n",
    "    tie_tol: float = 1e-9\n",
    "\n",
    "    # Loss / numeric policy\n",
    "    loss_type: str = \"huber\"\n",
    "    huber_beta: float = 1.0\n",
    "    eval_pred_clip: Optional[float] = None\n",
    "    nan_eps: float = 1e-12\n",
    "    nan_policy: str = \"fail_fast\"  # fail_fast | skip_epoch | skip_model\n",
    "\n",
    "    # Split\n",
    "    val_fraction: float = 0.15\n",
    "    test_fraction: float = 0.15\n",
    "    test_patterns: List[str] = field(default_factory=lambda: [\"human_coll\", \"coll\"])\n",
    "\n",
    "    # Tree baseline (XGBoost) fairness / evidence\n",
    "    et_n_estimators: int = 100\n",
    "    et_max_depth: Optional[int] = None\n",
    "    et_min_samples_leaf: int = 2\n",
    "    et_max_samples: int = 0  # 0 => use full training data (no subsampling)\n",
    "    et_builder: str = \"auto\"  # auto | memmap | in_memory\n",
    "    et_max_ram_mb: int = 3072\n",
    "    et_cv_splits: int = 0\n",
    "    et_shuffle_trials_endpoints: int = 0\n",
    "    et_shuffle_trials_flat_raw: int = 0\n",
    "    et_shuffle_trials_flat_stats: int = 0\n",
    "    et_warn_shuffle_r2: float = 0.20\n",
    "    et_fail_shuffle_r2: float = 0.35\n",
    "    et_zscore_warn: float = 2.0\n",
    "\n",
    "    # XGBoost GPU regressor params\n",
    "    xgb_n_estimators: int = 1200\n",
    "    xgb_max_depth: int = 8\n",
    "    xgb_learning_rate: float = 0.05\n",
    "    xgb_subsample: float = 0.90\n",
    "    xgb_colsample_bytree: float = 0.90\n",
    "    xgb_reg_alpha: float = 0.0\n",
    "    xgb_reg_lambda: float = 1.0\n",
    "    xgb_device: str = \"cuda\"\n",
    "    xgb_n_jobs_cpu: int = -1\n",
    "\n",
    "    # Physics-informed residual hybrid\n",
    "    run_physics_hybrid: bool = True\n",
    "    hybrid_model_name: str = \"tcn\"\n",
    "    hybrid_epochs: int = 60\n",
    "    hybrid_patience: int = 12\n",
    "    physics_alpha: float = 2.0\n",
    "    hybrid_plot_max_points: int = 8000\n",
    "\n",
    "    # Runtime / reproducibility\n",
    "    deterministic: bool = True\n",
    "    run_contract_checks: bool = True\n",
    "    run_loss_comparison: bool = False\n",
    "    loss_compare_epochs: int = 10\n",
    "\n",
    "    # Fast sanity mode (Colab)\n",
    "    quick_mode: bool = False\n",
    "    quick_train_trajectories: int = 10\n",
    "    quick_val_trajectories: int = 4\n",
    "    quick_test_trajectories: int = 4\n",
    "    quick_et_n_estimators: int = 80\n",
    "    quick_et_max_samples: int = 40_000\n",
    "    quick_xgb_n_estimators: int = 300\n",
    "\n",
    "    # Output\n",
    "    artifacts_dir: Path = field(default_factory=lambda: ARTIFACTS_DIR)\n",
    "    seed: int = 42\n",
    "\n",
    "\n",
    "config = TrainingConfig()\n",
    "\n",
    "RUN_QUICK_SANITY = False\n",
    "if RUN_QUICK_SANITY:\n",
    "    config.quick_mode = True\n",
    "\n",
    "if config.quick_mode:\n",
    "    config.epochs = max(20, min(config.epochs, 30))\n",
    "    config.min_epochs_before_stop = min(config.min_epochs_before_stop, 8)\n",
    "    config.patience = min(config.patience, 8)\n",
    "    config.train_stride = max(config.train_stride, 10)\n",
    "    config.eval_stride = max(config.eval_stride, 6)\n",
    "    config.batch_size = min(config.batch_size, 128)\n",
    "    config.channels = (32, 64, 64)\n",
    "    config.patch_d_model = min(config.patch_d_model, 96)\n",
    "    config.itr_d_model = min(config.itr_d_model, 96)\n",
    "    config.et_n_estimators = config.quick_et_n_estimators\n",
    "    config.xgb_n_estimators = config.quick_xgb_n_estimators\n",
    "    config.hybrid_epochs = min(config.hybrid_epochs, 25)\n",
    "    config.hybrid_patience = min(config.hybrid_patience, 8)\n",
    "    config.et_max_samples = config.quick_et_max_samples\n",
    "    config.et_shuffle_trials_endpoints = min(config.et_shuffle_trials_endpoints, 5)\n",
    "    config.et_shuffle_trials_flat_raw = min(config.et_shuffle_trials_flat_raw, 3)\n",
    "    config.et_shuffle_trials_flat_stats = min(config.et_shuffle_trials_flat_stats, 5)\n",
    "    if config.nan_policy == \"fail_fast\":\n",
    "        config.nan_policy = \"skip_model\"\n",
    "    print(\"Quick mode enabled: reduced compute for smoke testing.\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "np.random.seed(config.seed)\n",
    "random.seed(config.seed)\n",
    "torch.manual_seed(config.seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(config.seed)\n",
    "torch.backends.cudnn.deterministic = bool(config.deterministic)\n",
    "torch.backends.cudnn.benchmark = not bool(config.deterministic)\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(\"Configuration summary:\")\n",
    "print(f\"  Models: {config.model_names}\")\n",
    "print(f\"  Epochs: {config.epochs} (>=80 requirement satisfied: {config.epochs >= 80})\")\n",
    "print(f\"  Primary metric: {config.primary_metric} (minimize, original units)\")\n",
    "print(f\"  Secondary metric: {config.secondary_metric}\")\n",
    "print(f\"  Early stopping: patience={config.patience}, min_epochs={config.min_epochs_before_stop}, tie_tol={config.tie_tol}\")\n",
    "print(f\"  Deltas: primary={config.delta_primary_metric}, loss={config.delta_loss}\")\n",
    "print(f\"  NaN policy: {config.nan_policy} (eps={config.nan_eps})\")\n",
    "print(f\"  Strides: train={config.train_stride}, eval={config.eval_stride}\")\n",
    "print(f\"  ET builder={config.et_builder}, max_ram_mb={config.et_max_ram_mb}\")\n",
    "print(f\"Seed: {config.seed}, deterministic={config.deterministic}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f850d5",
   "metadata": {},
   "source": [
    "## 4. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb52ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_trajectories(\n",
    "    files: List[Path],\n",
    "    val_fraction: float = 0.15,\n",
    "    test_fraction: float = 0.15,\n",
    "    coll_patterns: Optional[List[str]] = None,\n",
    "    seed: int = 42,\n",
    ") -> Tuple[List[Path], List[Path], List[Path]]:\n",
    "    \"\"\"Deterministic stratified split by trajectory type (coll vs non-coll).\"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    patterns = [p.lower() for p in (coll_patterns or [\"coll\", \"human_coll\"]) if p]\n",
    "\n",
    "    stem_to_files = {}\n",
    "    for f in files:\n",
    "        stem_to_files.setdefault(f.stem, []).append(f)\n",
    "\n",
    "    duplicate_stems = sorted([s for s, lst in stem_to_files.items() if len(lst) > 1])\n",
    "    if duplicate_stems:\n",
    "        print(\n",
    "            f\"NOTE: Detected {len(duplicate_stems)} duplicate stems. \"\n",
    "            \"Splitting by stem to avoid cross-split contamination.\"\n",
    "        )\n",
    "        print(f\"  examples: {duplicate_stems[:15]}\")\n",
    "\n",
    "    def is_coll_stem(stem: str) -> bool:\n",
    "        st = stem.lower()\n",
    "        return any(pat in st for pat in patterns)\n",
    "\n",
    "    stems = sorted(stem_to_files.keys())\n",
    "    coll_stems = [s for s in stems if is_coll_stem(s)]\n",
    "    noncoll_stems = [s for s in stems if not is_coll_stem(s)]\n",
    "\n",
    "    def split_bucket(bucket: List[str]):\n",
    "        bucket = list(bucket)\n",
    "        rng.shuffle(bucket)\n",
    "        n = len(bucket)\n",
    "        if n == 0:\n",
    "            return [], [], []\n",
    "        if n == 1:\n",
    "            return bucket, [], []\n",
    "        if n == 2:\n",
    "            return [bucket[0]], [], [bucket[1]]\n",
    "        n_test = max(1, int(round(n * test_fraction)))\n",
    "        n_test = min(n_test, n - 2)\n",
    "        remaining = n - n_test\n",
    "        n_val = max(1, int(round(remaining * val_fraction)))\n",
    "        n_val = min(n_val, remaining - 1)\n",
    "        test = bucket[:n_test]\n",
    "        val = bucket[n_test:n_test + n_val]\n",
    "        train = bucket[n_test + n_val:]\n",
    "        return train, val, test\n",
    "\n",
    "    train_c, val_c, test_c = split_bucket(coll_stems)\n",
    "    train_n, val_n, test_n = split_bucket(noncoll_stems)\n",
    "\n",
    "    train_stems = train_c + train_n\n",
    "    val_stems = val_c + val_n\n",
    "    test_stems = test_c + test_n\n",
    "\n",
    "    def expand(stems_list: List[str]) -> List[Path]:\n",
    "        out = []\n",
    "        for s in stems_list:\n",
    "            out.extend(stem_to_files[s])\n",
    "        return out\n",
    "\n",
    "    train_files = expand(train_stems)\n",
    "    val_files = expand(val_stems)\n",
    "    test_files = expand(test_stems)\n",
    "\n",
    "    rng.shuffle(train_files)\n",
    "    rng.shuffle(val_files)\n",
    "    rng.shuffle(test_files)\n",
    "\n",
    "    if len(val_files) == 0 and len(train_files) > 1:\n",
    "        val_files.append(train_files.pop())\n",
    "    if len(test_files) == 0 and len(train_files) > 1:\n",
    "        test_files.append(train_files.pop())\n",
    "    if len(train_files) == 0 and len(val_files) > 0:\n",
    "        train_files.append(val_files.pop())\n",
    "\n",
    "    if len(coll_stems) > 0:\n",
    "        print(f\"Stratification (stems): coll={len(coll_stems)}, non-coll={len(noncoll_stems)}\")\n",
    "        print(f\"  coll split: train={len(train_c)} val={len(val_c)} test={len(test_c)}\")\n",
    "        print(f\"  non-coll:   train={len(train_n)} val={len(val_n)} test={len(test_n)}\")\n",
    "\n",
    "    return train_files, val_files, test_files\n",
    "\n",
    "\n",
    "def _to_2d_float64(x: np.ndarray) -> np.ndarray:\n",
    "    arr = np.asarray(x, dtype=np.float64)\n",
    "    if arr.ndim == 1:\n",
    "        arr = arr.reshape(-1, 1)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def _safe_quantile(values: np.ndarray, q: float, axis: int = 0):\n",
    "    try:\n",
    "        return np.nanquantile(values, q, axis=axis)\n",
    "    except Exception:\n",
    "        return np.full(values.shape[1] if values.ndim > 1 else 1, np.nan, dtype=np.float64)\n",
    "\n",
    "\n",
    "def compute_metrics(\n",
    "    y_true_orig: np.ndarray,\n",
    "    y_pred_orig: np.ndarray,\n",
    "    target_names: Optional[List[str]] = None,\n",
    "    nan_eps: float = 1e-12,\n",
    "    scaled_pair: Optional[Tuple[np.ndarray, np.ndarray]] = None,\n",
    ") -> Dict[str, object]:\n",
    "    \"\"\"Robust metrics with degenerate-target handling and explicit aggregates.\"\"\"\n",
    "    y_true = _to_2d_float64(y_true_orig)\n",
    "    y_pred = _to_2d_float64(y_pred_orig)\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise ValueError(f\"Shape mismatch y_true={y_true.shape}, y_pred={y_pred.shape}\")\n",
    "\n",
    "    n_targets = y_true.shape[1]\n",
    "    var_per_target = np.nanvar(y_true, axis=0)\n",
    "    valid_target_mask = np.isfinite(var_per_target) & (var_per_target > float(nan_eps))\n",
    "\n",
    "    r2_per_target = np.full(n_targets, np.nan, dtype=np.float64)\n",
    "    for idx in range(n_targets):\n",
    "        if not valid_target_mask[idx]:\n",
    "            continue\n",
    "        yt = y_true[:, idx]\n",
    "        yp = y_pred[:, idx]\n",
    "        finite = np.isfinite(yt) & np.isfinite(yp)\n",
    "        if np.count_nonzero(finite) < 2:\n",
    "            continue\n",
    "        try:\n",
    "            r2_per_target[idx] = float(r2_score(yt[finite], yp[finite]))\n",
    "        except Exception:\n",
    "            r2_per_target[idx] = np.nan\n",
    "\n",
    "    if np.any(valid_target_mask):\n",
    "        idx = np.flatnonzero(valid_target_mask)\n",
    "        finite_rows = np.isfinite(y_true[:, idx]).all(axis=1) & np.isfinite(y_pred[:, idx]).all(axis=1)\n",
    "        if np.count_nonzero(finite_rows) >= 2:\n",
    "            r2_vw_orig = float(\n",
    "                r2_score(\n",
    "                    y_true[finite_rows][:, idx],\n",
    "                    y_pred[finite_rows][:, idx],\n",
    "                    multioutput=\"variance_weighted\",\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            r2_vw_orig = np.nan\n",
    "    else:\n",
    "        r2_vw_orig = np.nan\n",
    "\n",
    "    r2_vw_scaled = np.nan\n",
    "    if scaled_pair is not None and np.any(valid_target_mask):\n",
    "        ys_true = _to_2d_float64(scaled_pair[0])\n",
    "        ys_pred = _to_2d_float64(scaled_pair[1])\n",
    "        if ys_true.shape == y_true.shape and ys_pred.shape == y_pred.shape:\n",
    "            idx = np.flatnonzero(valid_target_mask)\n",
    "            finite_rows = np.isfinite(ys_true[:, idx]).all(axis=1) & np.isfinite(ys_pred[:, idx]).all(axis=1)\n",
    "            if np.count_nonzero(finite_rows) >= 2:\n",
    "                try:\n",
    "                    r2_vw_scaled = float(\n",
    "                        r2_score(\n",
    "                            ys_true[finite_rows][:, idx],\n",
    "                            ys_pred[finite_rows][:, idx],\n",
    "                            multioutput=\"variance_weighted\",\n",
    "                        )\n",
    "                    )\n",
    "                except Exception:\n",
    "                    r2_vw_scaled = np.nan\n",
    "\n",
    "    r2_mean_orig = float(np.nanmean(r2_per_target)) if np.isfinite(r2_per_target).any() else np.nan\n",
    "    r2_median_orig = float(np.nanmedian(r2_per_target)) if np.isfinite(r2_per_target).any() else np.nan\n",
    "\n",
    "    diff = y_true - y_pred\n",
    "    abs_err = np.abs(diff)\n",
    "    rmse_per_target = np.sqrt(np.nanmean(diff ** 2, axis=0))\n",
    "    mae_per_target = np.nanmean(abs_err, axis=0)\n",
    "    max_abs_per_target = np.nanmax(abs_err, axis=0)\n",
    "    p99_abs_per_target = _safe_quantile(abs_err, 0.99, axis=0)\n",
    "\n",
    "    rmse = float(np.sqrt(np.nanmean(diff ** 2)))\n",
    "    mae = float(np.nanmean(abs_err))\n",
    "\n",
    "    result = {\n",
    "        \"r2\": float(r2_vw_orig) if np.isfinite(r2_vw_orig) else np.nan,\n",
    "        \"r2_vw_orig\": float(r2_vw_orig) if np.isfinite(r2_vw_orig) else np.nan,\n",
    "        \"r2_vw_scaled\": float(r2_vw_scaled) if np.isfinite(r2_vw_scaled) else np.nan,\n",
    "        \"r2_mean_orig\": float(r2_mean_orig) if np.isfinite(r2_mean_orig) else np.nan,\n",
    "        \"r2_median_orig\": float(r2_median_orig) if np.isfinite(r2_median_orig) else np.nan,\n",
    "        \"r2_per_target\": r2_per_target.astype(np.float64).tolist(),\n",
    "        \"valid_target_mask\": valid_target_mask.astype(bool).tolist(),\n",
    "        \"var_per_target\": var_per_target.astype(np.float64).tolist(),\n",
    "        \"valid_target_count\": int(np.count_nonzero(valid_target_mask)),\n",
    "        \"rmse\": float(rmse) if np.isfinite(rmse) else np.nan,\n",
    "        \"mae\": float(mae) if np.isfinite(mae) else np.nan,\n",
    "        \"rmse_per_target\": np.asarray(rmse_per_target, dtype=np.float64).tolist(),\n",
    "        \"mae_per_target\": np.asarray(mae_per_target, dtype=np.float64).tolist(),\n",
    "        \"max_abs_per_target\": np.asarray(max_abs_per_target, dtype=np.float64).tolist(),\n",
    "        \"p99_abs_per_target\": np.asarray(p99_abs_per_target, dtype=np.float64).tolist(),\n",
    "    }\n",
    "    if target_names is not None and len(target_names) == n_targets:\n",
    "        result[\"target_names\"] = list(target_names)\n",
    "    return result\n",
    "\n",
    "\n",
    "def compute_trajectory_weighted_metrics(\n",
    "    y_true_orig: np.ndarray,\n",
    "    y_pred_orig: np.ndarray,\n",
    "    window_groups: np.ndarray,\n",
    "    target_names: Optional[List[str]] = None,\n",
    "    nan_eps: float = 1e-12,\n",
    "    scaled_pair: Optional[Tuple[np.ndarray, np.ndarray]] = None,\n",
    "    target_scale: Optional[np.ndarray] = None,\n",
    ") -> Dict[str, object]:\n",
    "    \"\"\"Compute macro (trajectory-weighted) metrics where each trajectory has equal weight.\n",
    "\n",
    "    If target_scale is provided (e.g., train-set IQR in original units), also reports\n",
    "    normalized macro MAE metrics to prevent large-scale targets from dominating.\n",
    "    \"\"\"\n",
    "    y_true = _to_2d_float64(y_true_orig)\n",
    "    y_pred = _to_2d_float64(y_pred_orig)\n",
    "    groups = np.asarray(window_groups).reshape(-1)\n",
    "\n",
    "    if len(groups) != len(y_true):\n",
    "        raise ValueError(f\"window_groups length {len(groups)} != n_samples {len(y_true)}\")\n",
    "\n",
    "    uniq = np.unique(groups)\n",
    "    if len(uniq) == 0:\n",
    "        return {\n",
    "            \"n_trajectories\": 0,\n",
    "            \"traj_mae_orig\": np.nan,\n",
    "            \"traj_rmse_orig\": np.nan,\n",
    "            \"traj_r2_vw_orig\": np.nan,\n",
    "            \"traj_r2_median_orig\": np.nan,\n",
    "            \"traj_r2_per_target_mean\": [np.nan] * y_true.shape[1],\n",
    "            \"traj_macro_mae_per_target\": [np.nan] * y_true.shape[1],\n",
    "            \"traj_nmae_iqr\": np.nan,\n",
    "            \"traj_nmae_iqr_median_target\": np.nan,\n",
    "            \"traj_nmae_per_target\": [np.nan] * y_true.shape[1],\n",
    "        }\n",
    "\n",
    "    per_traj_metrics = []\n",
    "    per_traj_r2_matrix = []\n",
    "    per_traj_mae_per_target = []\n",
    "    windows_per_traj = {}\n",
    "\n",
    "    scaled_true = scaled_pair[0] if scaled_pair is not None else None\n",
    "    scaled_pred = scaled_pair[1] if scaled_pair is not None else None\n",
    "\n",
    "    for gid in uniq:\n",
    "        idx = np.flatnonzero(groups == gid)\n",
    "        windows_per_traj[int(gid)] = int(idx.size)\n",
    "        if idx.size == 0:\n",
    "            continue\n",
    "\n",
    "        sp = None\n",
    "        if scaled_true is not None and scaled_pred is not None:\n",
    "            sp = (np.asarray(scaled_true)[idx], np.asarray(scaled_pred)[idx])\n",
    "\n",
    "        m = compute_metrics(\n",
    "            y_true[idx],\n",
    "            y_pred[idx],\n",
    "            target_names=target_names,\n",
    "            nan_eps=nan_eps,\n",
    "            scaled_pair=sp,\n",
    "        )\n",
    "        per_traj_metrics.append(m)\n",
    "        per_traj_r2_matrix.append(np.asarray(m[\"r2_per_target\"], dtype=np.float64))\n",
    "        per_traj_mae_per_target.append(np.asarray(m[\"mae_per_target\"], dtype=np.float64))\n",
    "\n",
    "    if not per_traj_metrics:\n",
    "        return {\n",
    "            \"n_trajectories\": int(len(uniq)),\n",
    "            \"traj_mae_orig\": np.nan,\n",
    "            \"traj_rmse_orig\": np.nan,\n",
    "            \"traj_r2_vw_orig\": np.nan,\n",
    "            \"traj_r2_median_orig\": np.nan,\n",
    "            \"traj_r2_per_target_mean\": [np.nan] * y_true.shape[1],\n",
    "            \"traj_macro_mae_per_target\": [np.nan] * y_true.shape[1],\n",
    "            \"traj_nmae_iqr\": np.nan,\n",
    "            \"traj_nmae_iqr_median_target\": np.nan,\n",
    "            \"traj_nmae_per_target\": [np.nan] * y_true.shape[1],\n",
    "            \"windows_per_traj\": windows_per_traj,\n",
    "        }\n",
    "\n",
    "    traj_mae_vals = np.asarray([m[\"mae\"] for m in per_traj_metrics], dtype=np.float64)\n",
    "    traj_rmse_vals = np.asarray([m[\"rmse\"] for m in per_traj_metrics], dtype=np.float64)\n",
    "    traj_r2_vals = np.asarray([m[\"r2_vw_orig\"] for m in per_traj_metrics], dtype=np.float64)\n",
    "\n",
    "    r2_matrix = np.vstack(per_traj_r2_matrix) if per_traj_r2_matrix else np.empty((0, y_true.shape[1]))\n",
    "    mae_pt_matrix = np.vstack(per_traj_mae_per_target) if per_traj_mae_per_target else np.empty((0, y_true.shape[1]))\n",
    "    macro_mae_per_target = np.nanmean(mae_pt_matrix, axis=0) if mae_pt_matrix.size > 0 else np.full(y_true.shape[1], np.nan)\n",
    "\n",
    "    nmae_per_target = np.full(y_true.shape[1], np.nan, dtype=np.float64)\n",
    "    traj_nmae_iqr = np.nan\n",
    "    traj_nmae_iqr_median_target = np.nan\n",
    "\n",
    "    if target_scale is not None:\n",
    "        scale = np.asarray(target_scale, dtype=np.float64).reshape(-1)\n",
    "        if scale.shape[0] != y_true.shape[1]:\n",
    "            raise ValueError(f\"target_scale size {scale.shape[0]} != n_targets {y_true.shape[1]}\")\n",
    "        eps_scale = float(max(nan_eps, 1e-12))\n",
    "        valid_scale = np.isfinite(scale) & (scale > eps_scale)\n",
    "        nmae_per_target[valid_scale] = macro_mae_per_target[valid_scale] / scale[valid_scale]\n",
    "        if np.isfinite(nmae_per_target).any():\n",
    "            traj_nmae_iqr = float(np.nanmean(nmae_per_target))\n",
    "            traj_nmae_iqr_median_target = float(np.nanmedian(nmae_per_target))\n",
    "\n",
    "    return {\n",
    "        \"n_trajectories\": int(len(uniq)),\n",
    "        \"traj_mae_orig\": float(np.nanmean(traj_mae_vals)) if np.isfinite(traj_mae_vals).any() else np.nan,\n",
    "        \"traj_rmse_orig\": float(np.nanmean(traj_rmse_vals)) if np.isfinite(traj_rmse_vals).any() else np.nan,\n",
    "        \"traj_r2_vw_orig\": float(np.nanmean(traj_r2_vals)) if np.isfinite(traj_r2_vals).any() else np.nan,\n",
    "        \"traj_r2_median_orig\": float(np.nanmedian(traj_r2_vals)) if np.isfinite(traj_r2_vals).any() else np.nan,\n",
    "        \"traj_r2_per_target_mean\": np.nanmean(r2_matrix, axis=0).tolist() if r2_matrix.size > 0 else [np.nan] * y_true.shape[1],\n",
    "        \"traj_r2_per_target_median\": np.nanmedian(r2_matrix, axis=0).tolist() if r2_matrix.size > 0 else [np.nan] * y_true.shape[1],\n",
    "        \"traj_macro_mae_per_target\": np.asarray(macro_mae_per_target, dtype=np.float64).tolist(),\n",
    "        \"traj_nmae_iqr\": float(traj_nmae_iqr) if np.isfinite(traj_nmae_iqr) else np.nan,\n",
    "        \"traj_nmae_iqr_median_target\": float(traj_nmae_iqr_median_target) if np.isfinite(traj_nmae_iqr_median_target) else np.nan,\n",
    "        \"traj_nmae_per_target\": np.asarray(nmae_per_target, dtype=np.float64).tolist(),\n",
    "        \"windows_per_traj\": windows_per_traj,\n",
    "    }\n",
    "\n",
    "\n",
    "def extract_window_groups(dataset) -> np.ndarray:\n",
    "    return np.asarray([int(t) for t, _ in dataset.window_map], dtype=np.int32)\n",
    "\n",
    "\n",
    "LOWER_IS_BETTER_METRICS = {\n",
    "    \"traj_mae_orig\",\n",
    "    \"traj_rmse_orig\",\n",
    "    \"traj_nmae_iqr\",\n",
    "    \"traj_nmae_iqr_median_target\",\n",
    "    \"mae\",\n",
    "    \"rmse\",\n",
    "    \"val_loss\",\n",
    "}\n",
    "\n",
    "\n",
    "def metric_value_to_score(metric_name: str, metric_value: float) -> float:\n",
    "    if not np.isfinite(metric_value):\n",
    "        return np.nan\n",
    "    if metric_name in LOWER_IS_BETTER_METRICS:\n",
    "        return -float(metric_value)\n",
    "    return float(metric_value)\n",
    "\n",
    "\n",
    "def score_to_metric_value(metric_name: str, score_value: float) -> float:\n",
    "    if not np.isfinite(score_value):\n",
    "        return np.nan\n",
    "    if metric_name in LOWER_IS_BETTER_METRICS:\n",
    "        return -float(score_value)\n",
    "    return float(score_value)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, loss_fn, desc=\"Eval\", pred_clip: Optional[float] = None):\n",
    "    model.eval()\n",
    "    all_preds, all_targets = [], []\n",
    "    total_loss, n_batches = 0.0, 0\n",
    "\n",
    "    for x, y in tqdm(loader, desc=desc, leave=False):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x)\n",
    "        if pred_clip is not None:\n",
    "            pred = torch.clamp(pred, -pred_clip, pred_clip)\n",
    "        loss_val = loss_fn(pred, y)\n",
    "        total_loss += float(loss_val.item())\n",
    "        n_batches += 1\n",
    "        all_preds.append(pred.detach().cpu().numpy())\n",
    "        all_targets.append(y.detach().cpu().numpy())\n",
    "\n",
    "    if not all_preds:\n",
    "        return np.nan, np.empty((0, 0), dtype=np.float64), np.empty((0, 0), dtype=np.float64)\n",
    "    return (\n",
    "        total_loss / max(n_batches, 1),\n",
    "        np.concatenate(all_preds, axis=0),\n",
    "        np.concatenate(all_targets, axis=0),\n",
    "    )\n",
    "\n",
    "\n",
    "def _clone_state_dict(model: nn.Module):\n",
    "    try:\n",
    "        return {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "    except Exception as exc:\n",
    "        raise RuntimeError(f\"Failed to clone model state_dict to CPU: {exc}\") from exc\n",
    "\n",
    "\n",
    "def _load_checkpoint_state(path: Path):\n",
    "    return torch.load(path, map_location=\"cpu\")\n",
    "\n",
    "\n",
    "class DualMetricEarlyStopping:\n",
    "    \"\"\"Stop on no improvement in both loss and primary score; checkpoint by primary score.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        patience: int = 15,\n",
    "        min_epochs: int = 20,\n",
    "        delta_primary: float = 1e-3,\n",
    "        delta_loss: float = 1e-4,\n",
    "        checkpoint_path: Optional[Path] = None,\n",
    "    ):\n",
    "        self.patience = int(patience)\n",
    "        self.min_epochs = int(min_epochs)\n",
    "        self.delta_primary = float(delta_primary)\n",
    "        self.delta_loss = float(delta_loss)\n",
    "        self.counter = 0\n",
    "        self.best_primary_score = None\n",
    "        self.best_loss = None\n",
    "        self.best_epoch = 0\n",
    "        self.best_state = None\n",
    "        self.best_state_path = None\n",
    "        self.last_checkpoint_error = None\n",
    "        self.best_score = np.nan  # backward-compatible alias\n",
    "        self.should_stop = False\n",
    "        self.checkpoint_path = Path(checkpoint_path) if checkpoint_path is not None else None\n",
    "\n",
    "    def step(self, primary_score: float, loss_value: float, model: nn.Module, epoch: int) -> bool:\n",
    "        score_f = float(primary_score) if np.isfinite(primary_score) else np.nan\n",
    "        loss_f = float(loss_value) if np.isfinite(loss_value) else np.nan\n",
    "\n",
    "        improved_primary = False\n",
    "        improved_loss = False\n",
    "\n",
    "        if np.isfinite(loss_f):\n",
    "            if self.best_loss is None or loss_f < (self.best_loss - self.delta_loss):\n",
    "                improved_loss = True\n",
    "                self.best_loss = loss_f\n",
    "\n",
    "        if np.isfinite(score_f):\n",
    "            if self.best_primary_score is None or score_f > (self.best_primary_score + self.delta_primary):\n",
    "                improved_primary = True\n",
    "                self.best_primary_score = score_f\n",
    "                self.best_score = score_f\n",
    "                self.best_epoch = int(epoch)\n",
    "\n",
    "                # In-memory checkpoint (fast path)\n",
    "                try:\n",
    "                    self.best_state = _clone_state_dict(model)\n",
    "                    self.last_checkpoint_error = None\n",
    "                except Exception as exc:\n",
    "                    self.best_state = None\n",
    "                    self.last_checkpoint_error = str(exc)\n",
    "                    print(f\"WARNING: in-memory checkpoint copy failed at epoch {epoch}: {exc}\")\n",
    "\n",
    "                # Disk checkpoint fallback for long runs / copy failures\n",
    "                if self.checkpoint_path is not None:\n",
    "                    try:\n",
    "                        self.checkpoint_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                        torch.save(model.state_dict(), self.checkpoint_path)\n",
    "                        self.best_state_path = str(self.checkpoint_path)\n",
    "                    except Exception as exc:\n",
    "                        self.last_checkpoint_error = f\"disk checkpoint save failed: {exc}\"\n",
    "                        print(f\"WARNING: disk checkpoint save failed at epoch {epoch}: {exc}\")\n",
    "\n",
    "        if improved_primary or improved_loss:\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "\n",
    "        if epoch >= self.min_epochs and self.counter >= self.patience:\n",
    "            self.should_stop = True\n",
    "        return self.should_stop\n",
    "\n",
    "\n",
    "def validate_selection_consistency(history_values, selected_epoch: int, tie_tol: float = 1e-9) -> int:\n",
    "    \"\"\"NaN-explicit, tie-safe earliest-epoch consistency check.\"\"\"\n",
    "    h = np.asarray(history_values, dtype=np.float64)\n",
    "    if h.size == 0:\n",
    "        raise RuntimeError(\"no primary metric history recorded\")\n",
    "    if np.isnan(h).all():\n",
    "        raise RuntimeError(\"primary metric invalid across all epochs\")\n",
    "    best = np.nanmax(h)\n",
    "    tie_mask = np.isfinite(h) & (np.abs(h - best) <= float(tie_tol))\n",
    "    tie_idx = np.flatnonzero(tie_mask)\n",
    "    if tie_idx.size == 0:\n",
    "        raise RuntimeError(\n",
    "            f\"primary metric tie detection failed: best={best:.12g}, tie_tol={tie_tol}\"\n",
    "        )\n",
    "    expected_best_epoch = int(tie_idx[0]) + 1\n",
    "    if int(selected_epoch) != expected_best_epoch:\n",
    "        raise RuntimeError(\n",
    "            \"selection consistency check failed: \"\n",
    "            f\"selected_epoch={selected_epoch}, \"\n",
    "            f\"expected_best_epoch={expected_best_epoch}, \"\n",
    "            f\"best={best:.12g}, tie_tol={tie_tol}\"\n",
    "        )\n",
    "    return expected_best_epoch\n",
    "\n",
    "\n",
    "def set_global_seed(seed: int, deterministic: bool = True):\n",
    "    import random\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = bool(deterministic)\n",
    "    torch.backends.cudnn.benchmark = not bool(deterministic)\n",
    "\n",
    "\n",
    "def format_time(seconds):\n",
    "    return str(timedelta(seconds=int(seconds)))\n",
    "\n",
    "\n",
    "print(\"Helper functions ready: robust metrics, trajectory-weighted metrics, and tie-safe selection checks.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4445ddf",
   "metadata": {},
   "source": [
    "## 5. Load & Split Data by Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe92f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"LOADING DATA (Trajectory-Aware)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "files = list(config.data_dir.rglob(\"*.parquet\"))\n",
    "if not files:\n",
    "    raise FileNotFoundError(f\"No parquet files in {config.data_dir}\")\n",
    "print(f\"Found {len(files)} trajectory files\")\n",
    "\n",
    "# Filter to trajectories with ALL 6 F/T targets\n",
    "REQUIRED_TARGETS = [f'ft_{i}_eff' for i in range(1, 7)]\n",
    "\n",
    "print(\"Filtering trajectories with all 6 F/T targets...\")\n",
    "valid_files, skipped_files = [], []\n",
    "\n",
    "for f in tqdm(files, desc=\"Checking targets\"):\n",
    "    df = pd.read_parquet(f)\n",
    "    if all(col in df.columns for col in REQUIRED_TARGETS):\n",
    "        valid_files.append(f)\n",
    "    else:\n",
    "        skipped_files.append(f.stem)\n",
    "\n",
    "print(f\"âœ“ Valid: {len(valid_files)} trajectories\")\n",
    "if skipped_files:\n",
    "    print(f\"âœ— Skipped: {len(skipped_files)} (missing F/T targets)\")\n",
    "\n",
    "if not valid_files:\n",
    "    raise ValueError(\"No trajectories with all 6 F/T targets found!\")\n",
    "\n",
    "# Split by trajectory\n",
    "train_files, val_files, test_files = split_trajectories(\n",
    "    valid_files,\n",
    "    val_fraction=config.val_fraction,\n",
    "    test_fraction=config.test_fraction,\n",
    "    coll_patterns=config.test_patterns,\n",
    "    seed=config.seed,\n",
    ")\n",
    "\n",
    "if config.quick_mode:\n",
    "    rng_quick = np.random.RandomState(config.seed)\n",
    "    if len(train_files) > config.quick_train_trajectories:\n",
    "        train_files = list(rng_quick.choice(train_files, config.quick_train_trajectories, replace=False))\n",
    "    if len(val_files) > config.quick_val_trajectories:\n",
    "        val_files = list(rng_quick.choice(val_files, config.quick_val_trajectories, replace=False))\n",
    "    if len(test_files) > config.quick_test_trajectories:\n",
    "        test_files = list(rng_quick.choice(test_files, config.quick_test_trajectories, replace=False))\n",
    "    print(\"Quick mode split cap:\")\n",
    "    print(f\"  Train <= {config.quick_train_trajectories}\")\n",
    "    print(f\"  Val   <= {config.quick_val_trajectories}\")\n",
    "    print(f\"  Test  <= {config.quick_test_trajectories}\")\n",
    "\n",
    "print(f\"\\nSplit:\")\n",
    "print(f\"  Train: {len(train_files)} trajectories\")\n",
    "print(f\"  Val:   {len(val_files)} trajectories\")\n",
    "print(f\"  Test:  {len(test_files)} trajectories\")\n",
    "\n",
    "# Guardrail: R2 on tiny eval sets is unstable/misleading\n",
    "min_eval_trajectories = 2\n",
    "if len(val_files) < min_eval_trajectories or len(test_files) < min_eval_trajectories:\n",
    "    msg = (\n",
    "        f\"Insufficient eval trajectories for reliable validation: \"\n",
    "        f\"val={len(val_files)}, test={len(test_files)}, required>={min_eval_trajectories}.\"\n",
    "    )\n",
    "    if config.quick_mode:\n",
    "        print(f\"WARNING: {msg} Quick mode is for smoke tests only.\")\n",
    "    else:\n",
    "        raise ValueError(msg + \" Adjust split fractions or add more trajectory files.\")\n",
    "\n",
    "print(f\"\\nTest trajectory names:\")\n",
    "for f in sorted(test_files, key=lambda x: x.stem)[:10]:\n",
    "    print(f\"  - {f.stem}\")\n",
    "\n",
    "# ======================================================================\n",
    "# Phase 1 â€” Leakage/contamination checks (split disjointness + dupes)\n",
    "# ======================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SANITY CHECKS: SPLIT DISJOINTNESS & DUPLICATES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1) Split disjointness (by path + by stem)\n",
    "train_set, val_set, test_set = set(train_files), set(val_files), set(test_files)\n",
    "assert train_set.isdisjoint(val_set), f\"Split overlap: train vs val = {len(train_set & val_set)}\"\n",
    "assert train_set.isdisjoint(test_set), f\"Split overlap: train vs test = {len(train_set & test_set)}\"\n",
    "assert val_set.isdisjoint(test_set), f\"Split overlap: val vs test = {len(val_set & test_set)}\"\n",
    "\n",
    "train_stems = set(p.stem for p in train_files)\n",
    "val_stems   = set(p.stem for p in val_files)\n",
    "test_stems  = set(p.stem for p in test_files)\n",
    "assert train_stems.isdisjoint(val_stems), f\"Stem overlap: train vs val = {len(train_stems & val_stems)}\"\n",
    "assert train_stems.isdisjoint(test_stems), f\"Stem overlap: train vs test = {len(train_stems & test_stems)}\"\n",
    "assert val_stems.isdisjoint(test_stems), f\"Stem overlap: val vs test = {len(val_stems & test_stems)}\"\n",
    "\n",
    "print(\"OK: train/val/test splits are disjoint by path and stem.\")\n",
    "\n",
    "def _peek(items, n=8):\n",
    "    return [p.stem for p in sorted(items, key=lambda x: x.stem)[:n]]\n",
    "\n",
    "print(f\"  train examples: {_peek(train_files)}\")\n",
    "print(f\"  val examples:   {_peek(val_files)}\")\n",
    "print(f\"  test examples:  {_peek(test_files)}\")\n",
    "\n",
    "# 2) Cheap duplicate trajectory detection via Parquet metadata/statistics\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def _parquet_signature(path):\n",
    "    \"\"\"Return a cheap signature: (num_rows, t_min, t_max).\"\"\"\n",
    "    try:\n",
    "        import pyarrow.parquet as pq\n",
    "        pf = pq.ParquetFile(str(path))\n",
    "        md = pf.metadata\n",
    "        n_rows = int(md.num_rows)\n",
    "\n",
    "        schema_names = list(pf.schema_arrow.names)\n",
    "        if 't_s_base' not in schema_names:\n",
    "            return (n_rows, None, None)\n",
    "        col_idx = schema_names.index('t_s_base')\n",
    "\n",
    "        t_mins, t_maxs = [], []\n",
    "        for rg in range(md.num_row_groups):\n",
    "            st = md.row_group(rg).column(col_idx).statistics\n",
    "            if st is None:\n",
    "                continue\n",
    "            try:\n",
    "                if getattr(st, 'has_min_max', False):\n",
    "                    t_mins.append(st.min)\n",
    "                    t_maxs.append(st.max)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        if t_mins and t_maxs:\n",
    "            return (n_rows, float(min(t_mins)), float(max(t_maxs)))\n",
    "\n",
    "        # Fallback: read only the t_s_base column\n",
    "        tbl = pq.read_table(str(path), columns=['t_s_base'])\n",
    "        arr = tbl.column(0).to_numpy(zero_copy_only=False)\n",
    "        if len(arr) == 0:\n",
    "            return (n_rows, None, None)\n",
    "        return (n_rows, float(np.nanmin(arr)), float(np.nanmax(arr)))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "sig_map = defaultdict(list)\n",
    "n_sig = 0\n",
    "for p in valid_files:\n",
    "    sig = _parquet_signature(p)\n",
    "    if sig is None:\n",
    "        continue\n",
    "    sig_map[sig].append(p)\n",
    "    n_sig += 1\n",
    "\n",
    "dups = {k: v for k, v in sig_map.items() if len(v) > 1}\n",
    "if n_sig == 0:\n",
    "    print(\"NOTE: Duplicate signature check skipped (pyarrow unavailable or signatures failed).\")\n",
    "elif dups:\n",
    "    print(f\"WARNING: Potential duplicates by (n_rows, t_min, t_max): {len(dups)} signatures\")\n",
    "    shown = 0\n",
    "    for sig, paths in dups.items():\n",
    "        if shown >= 8:\n",
    "            break\n",
    "        stems = [p.stem for p in paths]\n",
    "        print(f\"  sig={sig} -> {stems[:10]}\")\n",
    "        shown += 1\n",
    "\n",
    "    # Cross-split duplicate evidence: same signature appearing in multiple splits\n",
    "    split_of = {p: 'train' for p in train_files}\n",
    "    split_of.update({p: 'val' for p in val_files})\n",
    "    split_of.update({p: 'test' for p in test_files})\n",
    "    cross = []\n",
    "    for sig, paths in dups.items():\n",
    "        splits = {split_of.get(p, '?') for p in paths}\n",
    "        if len(splits) > 1:\n",
    "            cross.append((sig, sorted(splits), paths))\n",
    "    if cross:\n",
    "        print(f\"WARNING: Potential CROSS-SPLIT duplicates by signature: {len(cross)} signatures\")\n",
    "        for sig, splits, paths in cross[:8]:\n",
    "            stems = [p.stem for p in paths]\n",
    "            print(f\"  sig={sig} splits={splits} -> {stems[:10]}\")\n",
    "else:\n",
    "    print(\"OK: No obvious duplicates by (n_rows, t_min, t_max) signature.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63afc08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trajectories(file_list):\n",
    "    dfs = []\n",
    "    for f in tqdm(file_list, desc=\"Loading\", leave=False):\n",
    "        df = pd.read_parquet(f)\n",
    "        try:\n",
    "            df['trajectory'] = str(f.relative_to(config.data_dir)).replace('\\\\', '/')\n",
    "        except Exception:\n",
    "            df['trajectory'] = str(f)\n",
    "        dfs.append(df)\n",
    "    return dfs\n",
    "\n",
    "print(\"Loading all trajectories...\")\n",
    "train_dfs = load_trajectories(train_files)\n",
    "val_dfs   = load_trajectories(val_files)\n",
    "test_dfs  = load_trajectories(test_files)\n",
    "\n",
    "total_train = sum(len(df) for df in train_dfs)\n",
    "total_val   = sum(len(df) for df in val_dfs)\n",
    "total_test  = sum(len(df) for df in test_dfs)\n",
    "print(f\"Samples: train={total_train:,}, val={total_val:,}, test={total_test:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf983d5",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a7a8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# IMPORTANT: Use causal (real-time) features to avoid time-lookahead inflation.\n",
    "CAUSAL_FEATURES = True\n",
    "\n",
    "# Make this notebook self-contained with respect to 'causal' vs 'non-causal'\n",
    "# feature engineering, even if the Drive copy of robot_data_pipeline is older.\n",
    "import inspect\n",
    "from dataclasses import fields, is_dataclass\n",
    "\n",
    "_cfg = dict(\n",
    "    compute_derivatives=True,\n",
    "    add_physics_features=True,\n",
    "    add_rolling_stats=True,\n",
    "    rolling_windows=[5, 10],\n",
    "    respect_trajectory_boundaries=True,\n",
    "    sort_by_time=True,\n",
    "    scaler_type='robust',\n",
    ")\n",
    "if CAUSAL_FEATURES:\n",
    "    _cfg.update(dict(rolling_center=False, derivative_method='finite_diff'))\n",
    "else:\n",
    "    _cfg.update(dict(rolling_center=True, derivative_method='savgol'))\n",
    "\n",
    "# Only pass FeatureConfig args that exist in the imported version.\n",
    "try:\n",
    "    if is_dataclass(FeatureConfig):\n",
    "        allowed = {f.name for f in fields(FeatureConfig)}\n",
    "    else:\n",
    "        allowed = set(inspect.signature(FeatureConfig).parameters.keys())\n",
    "    _cfg = {k: v for k, v in _cfg.items() if k in allowed}\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "fe_config = FeatureConfig(**_cfg)\n",
    "fe = FeatureEngineer(fe_config)\n",
    "\n",
    "def make_feature_engineer_causal(fe):\n",
    "    \"\"\"Monkeypatch FeatureEngineer to be strictly causal (past-only).\n",
    "\n",
    "    - Derivatives: backward finite differences\n",
    "    - Rolling stats: center=False\n",
    "    \"\"\"\n",
    "    import types\n",
    "    import numpy as np\n",
    "\n",
    "    def _compute_derivative(self, values, dt: float, order: int = 1):\n",
    "        dt = float(dt) if dt and dt > 0 else 1e-6\n",
    "        result = np.asarray(values, dtype=np.float64)\n",
    "        for _ in range(int(order)):\n",
    "            d = np.empty_like(result, dtype=np.float64)\n",
    "            d[0] = 0.0\n",
    "            d[1:] = (result[1:] - result[:-1]) / dt\n",
    "            result = d\n",
    "        return result\n",
    "\n",
    "    def _add_rolling_features(self, df):\n",
    "        df = df.copy()\n",
    "        eff_cols = self._get_joint_cols(self.JOINT_EFF_PATTERN)\n",
    "        vel_cols = self._get_joint_cols(self.JOINT_VEL_PATTERN)\n",
    "        windows = list(getattr(self.config, 'rolling_windows', [5, 10]))\n",
    "        for window in windows:\n",
    "            for col in eff_cols:\n",
    "                if col in df.columns:\n",
    "                    roll = df[col].rolling(window, center=False, min_periods=1)\n",
    "                    df[f'{col}_rmean_{window}'] = roll.mean()\n",
    "                    df[f'{col}_rstd_{window}'] = roll.std().fillna(0)\n",
    "            for col in vel_cols:\n",
    "                if col in df.columns:\n",
    "                    roll = df[col].rolling(window, center=False, min_periods=1)\n",
    "                    df[f'{col}_rmean_{window}'] = roll.mean()\n",
    "        return df\n",
    "\n",
    "    if hasattr(fe, '_compute_derivative'):\n",
    "        fe._compute_derivative = types.MethodType(_compute_derivative, fe)\n",
    "    if hasattr(fe, '_add_rolling_features'):\n",
    "        fe._add_rolling_features = types.MethodType(_add_rolling_features, fe)\n",
    "\n",
    "    # Best-effort: set config flags if present.\n",
    "    try:\n",
    "        fe.config.rolling_center = False\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        fe.config.derivative_method = 'finite_diff'\n",
    "    except Exception:\n",
    "        pass\n",
    "    return fe\n",
    "\n",
    "if CAUSAL_FEATURES:\n",
    "    fe = make_feature_engineer_causal(fe)\n",
    "\n",
    "# Fit on concatenated training data\n",
    "print(\"Fitting feature engineer on training data...\")\n",
    "train_combined = pd.concat(train_dfs, ignore_index=True)\n",
    "fe.fit(train_combined)\n",
    "\n",
    "all_feature_cols = fe.get_feature_names()\n",
    "all_target_cols  = fe.get_target_names()\n",
    "\n",
    "print(f\"Identified {len(all_feature_cols)} features, {len(all_target_cols)} targets\")\n",
    "print(f\"Targets: {all_target_cols}\")\n",
    "\n",
    "if len(all_target_cols) == 0:\n",
    "    raise ValueError(\"FeatureEngineer did not identify any target columns!\")\n",
    "\n",
    "# Check column consistency across a sample\n",
    "print(\"Checking column consistency...\")\n",
    "sample_dfs = train_dfs[:5] + val_dfs[:3] + test_dfs[:2]\n",
    "transformed_samples = [fe.transform(df.copy()) for df in sample_dfs]\n",
    "\n",
    "common_cols = set(transformed_samples[0].columns)\n",
    "for df in transformed_samples[1:]:\n",
    "    common_cols &= set(df.columns)\n",
    "\n",
    "print(f\"Found {len(common_cols)} common columns\")\n",
    "\n",
    "feature_cols = [c for c in all_feature_cols if c in common_cols]\n",
    "target_cols  = all_target_cols\n",
    "\n",
    "if not feature_cols:\n",
    "    raise ValueError(\"No common feature columns!\")\n",
    "\n",
    "# ======================================================================\n",
    "# Phase 2 â€” Hard \"target leakage\" checks (features accidentally include targets)\n",
    "# ======================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SANITY CHECKS: FEATURE/TARGET LEAKAGE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "overlap = sorted(set(feature_cols) & set(target_cols))\n",
    "if overlap:\n",
    "    raise ValueError(f\"FEATURE/TARGET OVERLAP (leakage): {overlap[:50]}\")\n",
    "\n",
    "FAIL_ON_SUSPICIOUS_FEATURES = True\n",
    "sus = []\n",
    "targets_l = [t.lower() for t in target_cols]\n",
    "for feat in feature_cols:\n",
    "    fl = feat.lower()\n",
    "    if 'ft_' in fl:\n",
    "        sus.append(feat)\n",
    "        continue\n",
    "    if any(t in fl for t in targets_l):\n",
    "        sus.append(feat)\n",
    "\n",
    "if sus:\n",
    "    print(f\"Suspicious features (contain 'ft_' or target substrings): {len(sus)}\")\n",
    "    print(sus[:80])\n",
    "    if FAIL_ON_SUSPICIOUS_FEATURES:\n",
    "        raise ValueError(\"Potential leakage: suspicious feature names detected. Remove/rename/disable these features.\")\n",
    "else:\n",
    "    print(\"OK: No feature/target overlap or obvious target-like feature names.\")\n",
    "\n",
    "# Fit scalers on consistent columns\n",
    "train_transformed = fe.transform(train_combined)\n",
    "train_clean = train_transformed.dropna(subset=feature_cols + target_cols)\n",
    "\n",
    "feature_scaler = RobustScaler()\n",
    "feature_scaler.fit(train_clean[feature_cols])\n",
    "\n",
    "# FIX: Use per-target scaler for better normalization\n",
    "print(\"\\nðŸ”§ Using PER-TARGET normalization (fixes scale imbalance)\")\n",
    "target_scaler = PerTargetScaler()\n",
    "target_scaler.fit(train_clean[target_cols].values, target_cols)\n",
    "\n",
    "# Target scales in original units (train-only) for normalized macro error metrics.\n",
    "train_target_orig = train_clean[target_cols].values.astype(np.float64)\n",
    "q25 = np.nanpercentile(train_target_orig, 25.0, axis=0)\n",
    "q75 = np.nanpercentile(train_target_orig, 75.0, axis=0)\n",
    "target_scale_iqr_orig = np.asarray(q75 - q25, dtype=np.float64)\n",
    "\n",
    "# Fallback for near-constant targets: use std if IQR is tiny, else eps floor.\n",
    "target_scale_std_orig = np.nanstd(train_target_orig, axis=0)\n",
    "eps_scale = float(max(config.nan_eps, 1e-12))\n",
    "use_std_mask = (~np.isfinite(target_scale_iqr_orig)) | (target_scale_iqr_orig <= eps_scale)\n",
    "target_scale_iqr_orig[use_std_mask] = target_scale_std_orig[use_std_mask]\n",
    "target_scale_iqr_orig = np.where(\n",
    "    np.isfinite(target_scale_iqr_orig) & (target_scale_iqr_orig > eps_scale),\n",
    "    target_scale_iqr_orig,\n",
    "    eps_scale,\n",
    ")\n",
    "\n",
    "print(\"Train target IQR scales (original units):\")\n",
    "for name, scale in zip(target_cols, target_scale_iqr_orig):\n",
    "    print(f\"  {name:12s}: {float(scale):.6f}\")\n",
    "\n",
    "del train_target_orig, q25, q75\n",
    "\n",
    "del train_combined, train_clean, train_transformed, transformed_samples\n",
    "\n",
    "# Transform each trajectory separately\n",
    "print(\"Transforming all trajectories...\")\n",
    "train_dfs = [fe.transform(df) for df in tqdm(train_dfs, desc=\"Train\", leave=False)]\n",
    "val_dfs   = [fe.transform(df) for df in tqdm(val_dfs,   desc=\"Val\",   leave=False)]\n",
    "test_dfs  = [fe.transform(df) for df in tqdm(test_dfs,  desc=\"Test\",  leave=False)]\n",
    "\n",
    "print(f\"\\nâœ“ Using {len(feature_cols)} features, {len(target_cols)} targets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d485e3ca",
   "metadata": {},
   "source": [
    "## 7. Create Trajectory-Aware Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fcd9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"CREATING TRAJECTORY-AWARE DATASETS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "train_ds, val_ds, test_ds = create_trajectory_datasets(\n",
    "    train_dfs, val_dfs, test_dfs,\n",
    "    feature_cols, target_cols,\n",
    "    feature_scaler, target_scaler,\n",
    "    seq_len=config.seq_len,\n",
    "    train_stride=config.train_stride,\n",
    "    eval_stride=config.eval_stride,\n",
    ")\n",
    "\n",
    "print(f\"\\nWindows (NO boundary crossing):\")\n",
    "print(f\"  Train: {len(train_ds):,} windows from {train_ds.n_trajectories} trajectories\")\n",
    "print(f\"  Val:   {len(val_ds):,} windows from {val_ds.n_trajectories} trajectories\")\n",
    "print(f\"  Test:  {len(test_ds):,} windows from {test_ds.n_trajectories} trajectories\")\n",
    "\n",
    "print(\"\\nValidating datasets...\")\n",
    "validate_no_boundary_crossing(train_ds)\n",
    "\n",
    "# Window-to-trajectory groups for trajectory-weighted validation metrics.\n",
    "train_window_groups = extract_window_groups(train_ds)\n",
    "val_window_groups = extract_window_groups(val_ds)\n",
    "test_window_groups = extract_window_groups(test_ds)\n",
    "\n",
    "assert len(train_window_groups) == len(train_ds), \"train group length mismatch\"\n",
    "assert len(val_window_groups) == len(val_ds), \"val group length mismatch\"\n",
    "assert len(test_window_groups) == len(test_ds), \"test group length mismatch\"\n",
    "\n",
    "print(f\"\\nTrajectory groups (windows):\")\n",
    "print(f\"  Train groups: {len(np.unique(train_window_groups))}\")\n",
    "print(f\"  Val groups:   {len(np.unique(val_window_groups))}\")\n",
    "print(f\"  Test groups:  {len(np.unique(test_window_groups))}\")\n",
    "\n",
    "# DataLoader\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=config.batch_size, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=config.batch_size, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=config.batch_size, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print(\"\\nDataLoaders ready (pin_memory=True for GPU)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c2d3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"DIAGNOSTICS: SCALED TARGETS & CLAMP RISK\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def _sample_y(loader, n_batches=20):\n",
    "    ys = []\n",
    "    for i, (_, y) in enumerate(loader):\n",
    "        if i >= n_batches:\n",
    "            break\n",
    "        ys.append(y.detach().cpu().numpy())\n",
    "    if not ys:\n",
    "        return None\n",
    "    return np.concatenate(ys, axis=0)\n",
    "\n",
    "def _describe_y(y, target_cols, clamp_values=(5.0, 10.0)):\n",
    "    if y is None:\n",
    "        print(\"No batches sampled.\")\n",
    "        return\n",
    "    print(f\"Sampled {len(y):,} targets (scaled) across {len(target_cols)} dims\")\n",
    "    for i, name in enumerate(target_cols):\n",
    "        col = y[:, i]\n",
    "        col = col[np.isfinite(col)]\n",
    "        if len(col) == 0:\n",
    "            print(f\"  {name}: no finite values\")\n",
    "            continue\n",
    "        p50, p90, p99, p999 = np.percentile(col, [50, 90, 99, 99.9])\n",
    "        mn, mx = float(np.min(col)), float(np.max(col))\n",
    "        frac5 = float(np.mean(np.abs(col) > clamp_values[0])) * 100.0\n",
    "        frac10 = float(np.mean(np.abs(col) > clamp_values[1])) * 100.0\n",
    "        print(f\"  {name:12s}  p50={p50:+.3f} p90={p90:+.3f} p99={p99:+.3f} p99.9={p999:+.3f}  min={mn:+.3f} max={mx:+.3f}  |y|>{clamp_values[0]:g}:{frac5:5.2f}%  |y|>{clamp_values[1]:g}:{frac10:5.2f}%\")\n",
    "\n",
    "def _baseline_mse(y, target_cols):\n",
    "    if y is None:\n",
    "        return\n",
    "    mse = np.mean(y ** 2, axis=0)\n",
    "    order = np.argsort(-mse)\n",
    "    print(\"\\nBaseline per-target MSE for pred=0 (scaled):\")\n",
    "    for idx in order:\n",
    "        print(f\"  {target_cols[idx]:12s}: {mse[idx]:.6f}\")\n",
    "\n",
    "def quick_per_target_model_loss(\n",
    "    model,\n",
    "    loader,\n",
    "    device,\n",
    "    target_cols,\n",
    "    loss_name=\"mse\",\n",
    "    huber_beta=1.0,\n",
    "    n_batches=10,\n",
    "    pred_clip=None,\n",
    "):\n",
    "    \"\"\"Compute per-target loss on a few batches to find dominating axes.\"\"\"\n",
    "    model.eval()\n",
    "    per_target = None\n",
    "    n = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(loader):\n",
    "            if i >= n_batches:\n",
    "                break\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x)\n",
    "            if pred_clip is not None:\n",
    "                pred = torch.clamp(pred, -pred_clip, pred_clip)\n",
    "\n",
    "            diff = pred - y\n",
    "            if loss_name.lower() in [\"huber\", \"smoothl1\", \"smooth_l1\"]:\n",
    "                abs_diff = diff.abs()\n",
    "                beta = float(huber_beta)\n",
    "                loss = torch.where(abs_diff < beta, 0.5 * (diff ** 2) / beta, abs_diff - 0.5 * beta)\n",
    "                loss_pt = loss.mean(dim=0)\n",
    "            else:\n",
    "                loss_pt = (diff ** 2).mean(dim=0)\n",
    "\n",
    "            per_target = loss_pt if per_target is None else per_target + loss_pt\n",
    "            n += 1\n",
    "\n",
    "    if per_target is None:\n",
    "        print(\"No batches sampled for model-loss diagnostic.\")\n",
    "        return\n",
    "\n",
    "    per_target = (per_target / max(n, 1)).detach().cpu().numpy()\n",
    "    order = np.argsort(-per_target)\n",
    "    print(f\"\\nModel per-target {loss_name} (avg over {n} batches):\")\n",
    "    for idx in order:\n",
    "        print(f\"  {target_cols[idx]:12s}: {per_target[idx]:.6f}\")\n",
    "\n",
    "N_DIAG_BATCHES = 20\n",
    "print(\"\\nTrain (scaled targets):\")\n",
    "y_train_diag = _sample_y(train_loader, n_batches=N_DIAG_BATCHES)\n",
    "_describe_y(y_train_diag, target_cols)\n",
    "_baseline_mse(y_train_diag, target_cols)\n",
    "\n",
    "print(\"\\nVal (scaled targets):\")\n",
    "y_val_diag = _sample_y(val_loader, n_batches=min(10, N_DIAG_BATCHES))\n",
    "_describe_y(y_val_diag, target_cols)\n",
    "_baseline_mse(y_val_diag, target_cols)\n",
    "\n",
    "print(\"\\nTip: If a noticeable fraction of samples have |y| > 10 (scaled),\")\n",
    "print(\"hard clamping predictions to [-10, 10] in TRAINING can stall learning\")\n",
    "print(\"because clamp has zero gradient outside the range.\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d37424",
   "metadata": {},
   "source": [
    "## 8. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d0ffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"MODEL FACTORIES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "class RevIN(nn.Module):\n",
    "    def __init__(self, num_features: int, eps: float = 1e-5, affine: bool = True):\n",
    "        super().__init__()\n",
    "        self.num_features = int(num_features)\n",
    "        self.eps = float(eps)\n",
    "        self.affine = bool(affine)\n",
    "        if self.affine:\n",
    "            self.gamma = nn.Parameter(torch.ones(1, 1, self.num_features))\n",
    "            self.beta = nn.Parameter(torch.zeros(1, 1, self.num_features))\n",
    "        self._last_mean = None\n",
    "        self._last_std = None\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mode: str = \"norm\") -> torch.Tensor:\n",
    "        if mode == \"norm\":\n",
    "            mean = x.mean(dim=1, keepdim=True)\n",
    "            std = x.std(dim=1, unbiased=False, keepdim=True).clamp_min(self.eps)\n",
    "            self._last_mean = mean.detach()\n",
    "            self._last_std = std.detach()\n",
    "            x_norm = (x - mean) / std\n",
    "            if self.affine:\n",
    "                x_norm = x_norm * self.gamma + self.beta\n",
    "            return x_norm\n",
    "        if mode == \"denorm\":\n",
    "            if self._last_mean is None or self._last_std is None:\n",
    "                return x\n",
    "            out = x\n",
    "            if self.affine:\n",
    "                out = (out - self.beta) / (self.gamma + self.eps)\n",
    "            return out * self._last_std + self._last_mean\n",
    "        raise ValueError(f\"Unknown RevIN mode: {mode}\")\n",
    "\n",
    "\n",
    "class PatchTSTRegressor(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features: int,\n",
    "        n_targets: int,\n",
    "        seq_len: int,\n",
    "        patch_len: int = 8,\n",
    "        patch_stride: int = 4,\n",
    "        d_model: int = 128,\n",
    "        n_heads: int = 8,\n",
    "        n_layers: int = 4,\n",
    "        ffn_dim: int = 256,\n",
    "        dropout: float = 0.1,\n",
    "        use_revin: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_features = int(n_features)\n",
    "        self.n_targets = int(n_targets)\n",
    "        self.seq_len = int(seq_len)\n",
    "        self.patch_len = int(min(max(2, patch_len), seq_len))\n",
    "        self.patch_stride = int(max(1, patch_stride))\n",
    "        self.d_model = int(d_model)\n",
    "        self.use_revin = bool(use_revin)\n",
    "\n",
    "        self.num_patches = ((self.seq_len - self.patch_len) // self.patch_stride) + 1\n",
    "        if self.num_patches <= 0:\n",
    "            raise ValueError(\"Invalid patch settings: num_patches <= 0\")\n",
    "\n",
    "        self.revin = RevIN(self.n_features, affine=False) if self.use_revin else None\n",
    "        self.patch_proj = nn.Linear(self.patch_len, self.d_model)\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, self.num_patches, self.d_model))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        layer = nn.TransformerEncoderLayer(\n",
    "            d_model=self.d_model,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=ffn_dim,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            norm_first=True,\n",
    "            activation=\"gelu\",\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(layer, num_layers=n_layers)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(self.n_features * self.d_model),\n",
    "            nn.Linear(self.n_features * self.d_model, self.n_targets),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.revin is not None:\n",
    "            x = self.revin(x, mode=\"norm\")\n",
    "        x = x.transpose(1, 2)\n",
    "        patches = x.unfold(dimension=2, size=self.patch_len, step=self.patch_stride)\n",
    "        bsz, n_feat, n_patch, patch_len = patches.shape\n",
    "        tokens = patches.contiguous().view(bsz * n_feat, n_patch, patch_len)\n",
    "        tokens = self.patch_proj(tokens)\n",
    "        tokens = self.dropout(tokens + self.pos_embed[:, :n_patch, :])\n",
    "        tokens = self.encoder(tokens)\n",
    "        pooled = tokens.mean(dim=1).view(bsz, n_feat, self.d_model)\n",
    "        out = self.head(pooled.reshape(bsz, n_feat * self.d_model))\n",
    "        return out\n",
    "\n",
    "\n",
    "class ITransformerRegressor(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features: int,\n",
    "        n_targets: int,\n",
    "        seq_len: int,\n",
    "        d_model: int = 128,\n",
    "        n_heads: int = 8,\n",
    "        n_layers: int = 4,\n",
    "        ffn_dim: int = 256,\n",
    "        dropout: float = 0.1,\n",
    "        use_revin: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_features = int(n_features)\n",
    "        self.n_targets = int(n_targets)\n",
    "        self.seq_len = int(seq_len)\n",
    "        self.d_model = int(d_model)\n",
    "        self.use_revin = bool(use_revin)\n",
    "\n",
    "        self.revin = RevIN(self.n_features, affine=False) if self.use_revin else None\n",
    "        self.time_proj = nn.Linear(self.seq_len, self.d_model)\n",
    "        self.var_embed = nn.Parameter(torch.zeros(1, self.n_features, self.d_model))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        layer = nn.TransformerEncoderLayer(\n",
    "            d_model=self.d_model,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=ffn_dim,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            norm_first=True,\n",
    "            activation=\"gelu\",\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(layer, num_layers=n_layers)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(self.n_features * self.d_model),\n",
    "            nn.Linear(self.n_features * self.d_model, self.n_targets),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.revin is not None:\n",
    "            x = self.revin(x, mode=\"norm\")\n",
    "        tokens = x.transpose(1, 2)\n",
    "        tokens = self.time_proj(tokens)\n",
    "        tokens = self.dropout(tokens + self.var_embed)\n",
    "        tokens = self.encoder(tokens)\n",
    "        out = self.head(tokens.reshape(tokens.shape[0], -1))\n",
    "        return out\n",
    "\n",
    "\n",
    "def count_trainable_params(model: nn.Module) -> int:\n",
    "    return int(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "\n",
    "def make_model(model_name: str) -> nn.Module:\n",
    "    name = str(model_name).lower().strip()\n",
    "    if name == \"tcn\":\n",
    "        return OptimizedTCN(\n",
    "            n_features=len(feature_cols),\n",
    "            n_targets=len(target_cols),\n",
    "            channels=config.channels,\n",
    "            kernel_size=config.kernel_size,\n",
    "            dropout=config.dropout,\n",
    "        )\n",
    "    if name == \"patchtst\":\n",
    "        return PatchTSTRegressor(\n",
    "            n_features=len(feature_cols),\n",
    "            n_targets=len(target_cols),\n",
    "            seq_len=config.seq_len,\n",
    "            patch_len=config.patch_len,\n",
    "            patch_stride=config.patch_stride,\n",
    "            d_model=config.patch_d_model,\n",
    "            n_heads=config.patch_n_heads,\n",
    "            n_layers=config.patch_n_layers,\n",
    "            ffn_dim=config.patch_ffn_dim,\n",
    "            dropout=config.patch_dropout,\n",
    "            use_revin=config.patch_use_revin,\n",
    "        )\n",
    "    if name == \"itransformer\":\n",
    "        return ITransformerRegressor(\n",
    "            n_features=len(feature_cols),\n",
    "            n_targets=len(target_cols),\n",
    "            seq_len=config.seq_len,\n",
    "            d_model=config.itr_d_model,\n",
    "            n_heads=config.itr_n_heads,\n",
    "            n_layers=config.itr_n_layers,\n",
    "            ffn_dim=config.itr_ffn_dim,\n",
    "            dropout=config.itr_dropout,\n",
    "            use_revin=config.itr_use_revin,\n",
    "        )\n",
    "    raise ValueError(f\"Unknown model name: {model_name}\")\n",
    "\n",
    "\n",
    "def get_model_lr(model_name: str) -> float:\n",
    "    name = str(model_name).lower().strip()\n",
    "    if name == \"tcn\":\n",
    "        return float(config.lr_tcn)\n",
    "    if name == \"patchtst\":\n",
    "        return float(config.lr_patchtst)\n",
    "    if name == \"itransformer\":\n",
    "        return float(config.lr_itransformer)\n",
    "    return float(config.lr_tcn)\n",
    "\n",
    "\n",
    "valid_models = []\n",
    "seen_models = set()\n",
    "for raw_name in config.model_names:\n",
    "    name = str(raw_name).lower().strip()\n",
    "    if name in seen_models:\n",
    "        continue\n",
    "    if name not in {\"tcn\", \"patchtst\", \"itransformer\"}:\n",
    "        raise ValueError(f\"Unsupported model in config.model_names: {raw_name}\")\n",
    "    valid_models.append(name)\n",
    "    seen_models.add(name)\n",
    "config.model_names = tuple(valid_models)\n",
    "\n",
    "model_builders = {name: (lambda n=name: make_model(n)) for name in config.model_names}\n",
    "\n",
    "print(\"Configured models:\")\n",
    "for model_name in config.model_names:\n",
    "    preview_model = model_builders[model_name]().to(device)\n",
    "    n_params = count_trainable_params(preview_model)\n",
    "    extra = \"\"\n",
    "    if model_name == \"tcn\" and hasattr(preview_model, \"get_receptive_field\"):\n",
    "        extra = f\", receptive_field={preview_model.get_receptive_field()}\"\n",
    "    print(f\"  - {model_name:12s} params={n_params:,} lr={get_model_lr(model_name):.2e}{extra}\")\n",
    "    del preview_model\n",
    "\n",
    "model = None\n",
    "print(f\"Primary metric for checkpoint selection: {config.primary_metric}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c0e4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"CONTRACT CHECKS + OPTIONAL LOSS COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "def _run_deep_window_alignment_contract():\n",
    "    seq_len = 4\n",
    "    stride = 2\n",
    "    n = 14\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"feat\": np.arange(n, dtype=np.float64),\n",
    "            \"target\": np.arange(n, dtype=np.float64),\n",
    "            \"trajectory\": [\"synthetic_deep\"] * n,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    feat_scaler = RobustScaler().fit(df[[\"feat\"]].values)\n",
    "    tgt_scaler = PerTargetScaler().fit(df[[\"target\"]].values, [\"target\"])\n",
    "\n",
    "    ds_train, ds_val, ds_test = create_trajectory_datasets(\n",
    "        [df], [df], [df],\n",
    "        feature_cols=[\"feat\"],\n",
    "        target_cols=[\"target\"],\n",
    "        feature_scaler=feat_scaler,\n",
    "        target_scaler=tgt_scaler,\n",
    "        seq_len=seq_len,\n",
    "        train_stride=stride,\n",
    "        eval_stride=stride,\n",
    "    )\n",
    "    expected = np.arange(seq_len - 1, n, stride).tolist()\n",
    "    observed = []\n",
    "    for i in range(len(ds_train)):\n",
    "        _, y = ds_train[i]\n",
    "        if torch.is_tensor(y):\n",
    "            y_np = y.detach().cpu().numpy().reshape(1, -1)\n",
    "        else:\n",
    "            y_np = np.asarray(y).reshape(1, -1)\n",
    "        y_orig = tgt_scaler.inverse_transform(y_np)[0, 0]\n",
    "        observed.append(int(round(float(y_orig))))\n",
    "\n",
    "    if observed != expected:\n",
    "        raise RuntimeError(\n",
    "            f\"Deep window alignment failed: expected={expected[:10]} observed={observed[:10]}\"\n",
    "        )\n",
    "    print(\"Deep window alignment contract: PASS\")\n",
    "\n",
    "\n",
    "if config.run_contract_checks:\n",
    "    _run_deep_window_alignment_contract()\n",
    "else:\n",
    "    print(\"Contract checks disabled by config.run_contract_checks=False\")\n",
    "\n",
    "if not config.run_loss_comparison:\n",
    "    print(\"Loss comparison skipped (config.run_loss_comparison=False).\")\n",
    "else:\n",
    "    from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "    def _make_loss(loss_type: str):\n",
    "        lt = (loss_type or \"mse\").lower()\n",
    "        if lt in [\"huber\", \"smoothl1\", \"smooth_l1\"]:\n",
    "            return nn.SmoothL1Loss(beta=config.huber_beta)\n",
    "        return nn.MSELoss()\n",
    "\n",
    "    def _run_short(loss_type: str, epochs: int):\n",
    "        set_global_seed(config.seed, deterministic=config.deterministic)\n",
    "        m = make_model(\"tcn\").to(device)\n",
    "        opt = torch.optim.AdamW(\n",
    "            m.parameters(),\n",
    "            lr=get_model_lr(\"tcn\"),\n",
    "            weight_decay=config.weight_decay,\n",
    "        )\n",
    "        sched = CosineAnnealingLR(opt, T_max=max(1, epochs), eta_min=1e-6)\n",
    "        lf = _make_loss(loss_type)\n",
    "        best_r2 = -np.inf\n",
    "        best_ep = 0\n",
    "\n",
    "        for ep in range(1, epochs + 1):\n",
    "            m.train()\n",
    "            for x, y in train_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                opt.zero_grad()\n",
    "                pred = m(x)\n",
    "                loss = lf(pred, y)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(m.parameters(), config.gradient_clip)\n",
    "                opt.step()\n",
    "            _, v_pred, v_tgt = evaluate(m, val_loader, device, lf, desc=f\"cmp-{loss_type}-{ep:02d}\")\n",
    "            v_pred_o = target_scaler.inverse_transform(v_pred)\n",
    "            v_tgt_o = target_scaler.inverse_transform(v_tgt)\n",
    "            metrics = compute_metrics(\n",
    "                v_tgt_o,\n",
    "                v_pred_o,\n",
    "                target_names=target_cols,\n",
    "                nan_eps=config.nan_eps,\n",
    "                scaled_pair=(v_tgt, v_pred),\n",
    "            )\n",
    "            r2_val = metrics[\"r2_vw_orig\"]\n",
    "            if np.isfinite(r2_val) and r2_val > best_r2:\n",
    "                best_r2 = float(r2_val)\n",
    "                best_ep = ep\n",
    "            sched.step()\n",
    "        return {\"loss\": loss_type, \"best_r2_vw_orig\": best_r2, \"best_epoch\": best_ep}\n",
    "\n",
    "    cmp_epochs = int(max(3, config.loss_compare_epochs))\n",
    "    print(f\"Running short loss comparison for {cmp_epochs} epochs...\")\n",
    "    for lt in [\"mse\", \"huber\"]:\n",
    "        result = _run_short(lt, cmp_epochs)\n",
    "        print(\n",
    "            f\"  {result['loss']:>5s}: best_r2_vw_orig={result['best_r2_vw_orig']:.5f} \"\n",
    "            f\"at epoch {result['best_epoch']}\"\n",
    "        )\n",
    "\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eda6992",
   "metadata": {},
   "source": [
    "## 9. Train with Improved Settings!\n",
    "\n",
    "**Key Improvements in Training Loop:**\n",
    "- âœ… Learning rate warmup (5 epochs)\n",
    "- âœ… Gradient monitoring with auto-skip\n",
    "- âœ… No hard prediction clamp in TRAINING (prevents zero-grad stalls)\n",
    "- âœ… Robust loss (Huber / SmoothL1)\n",
    "- âœ… Enhanced logging (shows LR, max_grad, issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea7c142",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TRAINING (MULTI-MODEL, ROBUST CHECKPOINTING)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "\n",
    "def make_loss(loss_type: str):\n",
    "    lt = (loss_type or \"mse\").lower()\n",
    "    if lt in [\"huber\", \"smoothl1\", \"smooth_l1\"]:\n",
    "        return nn.SmoothL1Loss(beta=float(config.huber_beta))\n",
    "    if lt in [\"mse\", \"l2\"]:\n",
    "        return nn.MSELoss()\n",
    "    raise ValueError(f\"Unknown loss_type={loss_type}\")\n",
    "\n",
    "\n",
    "loss_fn = make_loss(config.loss_type)\n",
    "\n",
    "\n",
    "def _prepare_scheduler(optimizer, base_lr: float):\n",
    "    warmup_epochs = int(max(0, config.warmup_epochs))\n",
    "    warmup_start_factor = 0.1\n",
    "\n",
    "    def warmup_lr(epoch: int) -> float:\n",
    "        if warmup_epochs <= 1:\n",
    "            return float(base_lr)\n",
    "        t = (epoch - 1) / float(max(1, warmup_epochs - 1))\n",
    "        t = max(0.0, min(1.0, t))\n",
    "        factor = warmup_start_factor + t * (1.0 - warmup_start_factor)\n",
    "        return float(base_lr * factor)\n",
    "\n",
    "    if warmup_epochs > 0:\n",
    "        lr0 = warmup_lr(1)\n",
    "        for pg in optimizer.param_groups:\n",
    "            pg[\"lr\"] = lr0\n",
    "    scheduler = None\n",
    "    if warmup_epochs <= 0:\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=max(1, config.epochs), eta_min=1e-6)\n",
    "    return scheduler, warmup_epochs, warmup_lr\n",
    "\n",
    "\n",
    "def _step_scheduler(epoch: int, optimizer, scheduler, warmup_epochs: int, warmup_lr_fn, base_lr: float):\n",
    "    if warmup_epochs > 0 and epoch < warmup_epochs:\n",
    "        next_lr = warmup_lr_fn(epoch + 1)\n",
    "        for pg in optimizer.param_groups:\n",
    "            pg[\"lr\"] = next_lr\n",
    "        return scheduler, float(next_lr)\n",
    "    if warmup_epochs > 0 and epoch == warmup_epochs:\n",
    "        for pg in optimizer.param_groups:\n",
    "            pg[\"lr\"] = float(base_lr)\n",
    "        scheduler = CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=max(1, config.epochs - warmup_epochs),\n",
    "            eta_min=1e-6,\n",
    "        )\n",
    "        return scheduler, float(optimizer.param_groups[0][\"lr\"])\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    return scheduler, float(optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "\n",
    "def _resolve_metric_value(metric_name: str, global_metrics: dict, traj_metrics: dict) -> float:\n",
    "    if metric_name in traj_metrics:\n",
    "        return float(traj_metrics[metric_name])\n",
    "    if metric_name in global_metrics:\n",
    "        return float(global_metrics[metric_name])\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def train_one_model(model_name: str, seed_offset: int = 0):\n",
    "    run_seed = int(config.seed + seed_offset)\n",
    "    set_global_seed(run_seed, deterministic=config.deterministic)\n",
    "    model_local = model_builders[model_name]().to(device)\n",
    "    model_lr = get_model_lr(model_name)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model_local.parameters(),\n",
    "        lr=float(model_lr),\n",
    "        weight_decay=float(config.weight_decay),\n",
    "    )\n",
    "    scheduler, warmup_epochs, warmup_lr_fn = _prepare_scheduler(optimizer, float(model_lr))\n",
    "\n",
    "    best_ckpt_path = config.artifacts_dir / \"_tmp_best_states\" / f\"{model_name}_seed{run_seed}_best.pt\"\n",
    "    stopper = DualMetricEarlyStopping(\n",
    "        patience=config.patience,\n",
    "        min_epochs=config.min_epochs_before_stop,\n",
    "        delta_primary=config.delta_primary_metric,\n",
    "        delta_loss=config.delta_loss,\n",
    "        checkpoint_path=best_ckpt_path,\n",
    "    )\n",
    "\n",
    "    history_local = {\n",
    "        \"train_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_primary_metric\": [],\n",
    "        \"val_primary_score\": [],\n",
    "        \"val_secondary_metric\": [],\n",
    "        \"val_r2_vw_orig\": [],\n",
    "        \"val_r2_vw_scaled\": [],\n",
    "        \"val_r2_mean_orig\": [],\n",
    "        \"val_r2_median_orig\": [],\n",
    "        \"val_traj_mae_orig\": [],\n",
    "        \"val_traj_nmae_iqr\": [],\n",
    "        \"val_traj_nmae_iqr_median_target\": [],\n",
    "        \"val_traj_rmse_orig\": [],\n",
    "        \"val_traj_r2_vw_orig\": [],\n",
    "        \"val_traj_r2_median_orig\": [],\n",
    "        \"val_rmse\": [],\n",
    "        \"val_mae\": [],\n",
    "        \"lr_used\": [],\n",
    "        \"lr_next\": [],\n",
    "        \"max_grad_pre\": [],\n",
    "        \"max_grad_post\": [],\n",
    "        \"grad_issues\": [],\n",
    "        \"epoch_seconds\": [],\n",
    "    }\n",
    "\n",
    "    print(f\"\\n[{model_name}] Optimizer=AdamW lr={model_lr:.2e} wd={config.weight_decay}\")\n",
    "    print(\n",
    "        f\"[{model_name}] Selection: primary={config.primary_metric} (delta={config.delta_primary_metric}), \"\n",
    "        f\"secondary={config.secondary_metric}, stop_loss_delta={config.delta_loss}\"\n",
    "    )\n",
    "    print(f\"[{model_name}] Loss={config.loss_type} (huber_beta={config.huber_beta}), grad_clip={config.gradient_clip}\")\n",
    "\n",
    "    model_start = time.time()\n",
    "    skip_model_reason = None\n",
    "\n",
    "    for epoch in range(1, config.epochs + 1):\n",
    "        epoch_start = time.time()\n",
    "        current_lr = float(optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "        model_local.train()\n",
    "        total_loss = 0.0\n",
    "        n_batches = 0\n",
    "        max_grad_pre_epoch = 0.0\n",
    "        max_grad_post_epoch = 0.0\n",
    "        n_grad_issues = 0\n",
    "\n",
    "        for x, y in tqdm(train_loader, desc=f\"{model_name} Epoch {epoch:3d}/{config.epochs}\", leave=False):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            # [CRITICAL FIX] Safety clamp for rare extreme target outliers\n",
    "            y = torch.clamp(y, -10.0, 10.0)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            pred = model_local(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "            loss.backward()\n",
    "\n",
    "            max_grad_pre, has_nan, has_inf = check_gradients(model_local)\n",
    "            max_grad_pre_epoch = max(max_grad_pre_epoch, float(max_grad_pre))\n",
    "\n",
    "            if has_nan or has_inf:\n",
    "                n_grad_issues += 1\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                continue\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model_local.parameters(), float(config.gradient_clip))\n",
    "            max_grad_post, _, _ = check_gradients(model_local)\n",
    "            max_grad_post_epoch = max(max_grad_post_epoch, float(max_grad_post))\n",
    "\n",
    "            optimizer.step()\n",
    "            total_loss += float(loss.item())\n",
    "            n_batches += 1\n",
    "\n",
    "        train_loss = total_loss / max(1, n_batches)\n",
    "\n",
    "        val_loss, val_preds_scaled, val_targets_scaled = evaluate(\n",
    "            model_local,\n",
    "            val_loader,\n",
    "            device,\n",
    "            loss_fn,\n",
    "            desc=f\"{model_name} Val {epoch:3d}\",\n",
    "            pred_clip=config.eval_pred_clip,\n",
    "        )\n",
    "        val_preds_orig = target_scaler.inverse_transform(val_preds_scaled)\n",
    "        val_targets_orig = target_scaler.inverse_transform(val_targets_scaled)\n",
    "\n",
    "        val_metrics = compute_metrics(\n",
    "            val_targets_orig,\n",
    "            val_preds_orig,\n",
    "            target_names=target_cols,\n",
    "            nan_eps=config.nan_eps,\n",
    "            scaled_pair=(val_targets_scaled, val_preds_scaled),\n",
    "        )\n",
    "        val_traj_metrics = compute_trajectory_weighted_metrics(\n",
    "            val_targets_orig,\n",
    "            val_preds_orig,\n",
    "            window_groups=val_window_groups,\n",
    "            target_names=target_cols,\n",
    "            nan_eps=config.nan_eps,\n",
    "            scaled_pair=(val_targets_scaled, val_preds_scaled),\n",
    "            target_scale=target_scale_iqr_orig,\n",
    "        )\n",
    "\n",
    "        primary_value = _resolve_metric_value(config.primary_metric, val_metrics, val_traj_metrics)\n",
    "        secondary_value = _resolve_metric_value(config.secondary_metric, val_metrics, val_traj_metrics)\n",
    "        primary_score = metric_value_to_score(config.primary_metric, primary_value)\n",
    "\n",
    "        if not np.isfinite(primary_value):\n",
    "            msg = (\n",
    "                f\"[{model_name}] primary metric invalid at epoch {epoch}: \"\n",
    "                f\"{config.primary_metric}={primary_value}, valid_targets={val_metrics.get('valid_target_count')}\"\n",
    "            )\n",
    "            if config.nan_policy == \"fail_fast\":\n",
    "                raise RuntimeError(msg)\n",
    "            if config.nan_policy == \"skip_model\":\n",
    "                skip_model_reason = msg\n",
    "                print(f\"WARNING: {msg} -> skip_model\")\n",
    "                break\n",
    "            print(f\"WARNING: {msg} -> skip_epoch\")\n",
    "\n",
    "        history_local[\"train_loss\"].append(float(np.float64(train_loss)))\n",
    "        history_local[\"val_loss\"].append(float(np.float64(val_loss)))\n",
    "        history_local[\"val_primary_metric\"].append(float(np.float64(primary_value)))\n",
    "        history_local[\"val_primary_score\"].append(float(np.float64(primary_score)))\n",
    "        history_local[\"val_secondary_metric\"].append(float(np.float64(secondary_value)))\n",
    "\n",
    "        history_local[\"val_r2_vw_orig\"].append(float(np.float64(val_metrics[\"r2_vw_orig\"])))\n",
    "        history_local[\"val_r2_vw_scaled\"].append(float(np.float64(val_metrics[\"r2_vw_scaled\"])))\n",
    "        history_local[\"val_r2_mean_orig\"].append(float(np.float64(val_metrics[\"r2_mean_orig\"])))\n",
    "        history_local[\"val_r2_median_orig\"].append(float(np.float64(val_metrics[\"r2_median_orig\"])))\n",
    "        history_local[\"val_traj_mae_orig\"].append(float(np.float64(val_traj_metrics[\"traj_mae_orig\"])))\n",
    "        history_local[\"val_traj_nmae_iqr\"].append(float(np.float64(val_traj_metrics[\"traj_nmae_iqr\"])))\n",
    "        history_local[\"val_traj_nmae_iqr_median_target\"].append(float(np.float64(val_traj_metrics[\"traj_nmae_iqr_median_target\"])))\n",
    "        history_local[\"val_traj_rmse_orig\"].append(float(np.float64(val_traj_metrics[\"traj_rmse_orig\"])))\n",
    "        history_local[\"val_traj_r2_vw_orig\"].append(float(np.float64(val_traj_metrics[\"traj_r2_vw_orig\"])))\n",
    "        history_local[\"val_traj_r2_median_orig\"].append(float(np.float64(val_traj_metrics[\"traj_r2_median_orig\"])))\n",
    "\n",
    "        history_local[\"val_rmse\"].append(float(np.float64(val_metrics[\"rmse\"])))\n",
    "        history_local[\"val_mae\"].append(float(np.float64(val_metrics[\"mae\"])))\n",
    "        history_local[\"lr_used\"].append(float(np.float64(current_lr)))\n",
    "        history_local[\"max_grad_pre\"].append(float(np.float64(max_grad_pre_epoch)))\n",
    "        history_local[\"max_grad_post\"].append(float(np.float64(max_grad_post_epoch)))\n",
    "        history_local[\"grad_issues\"].append(int(n_grad_issues))\n",
    "\n",
    "        scheduler, next_lr = _step_scheduler(\n",
    "            epoch,\n",
    "            optimizer,\n",
    "            scheduler,\n",
    "            warmup_epochs,\n",
    "            warmup_lr_fn,\n",
    "            base_lr=float(model_lr),\n",
    "        )\n",
    "        history_local[\"lr_next\"].append(float(np.float64(next_lr)))\n",
    "\n",
    "        should_stop = stopper.step(\n",
    "            primary_score=float(primary_score),\n",
    "            loss_value=float(val_loss),\n",
    "            model=model_local,\n",
    "            epoch=epoch,\n",
    "        )\n",
    "\n",
    "        epoch_seconds = float(time.time() - epoch_start)\n",
    "        history_local[\"epoch_seconds\"].append(epoch_seconds)\n",
    "\n",
    "        grad_warn = f\" grad_issues={n_grad_issues}\" if n_grad_issues > 0 else \"\"\n",
    "        print(\n",
    "            f\"[{model_name}] Epoch {epoch:3d}/{config.epochs} | \"\n",
    "            f\"loss={train_loss:.5f} | \"\n",
    "            f\"{config.primary_metric}={primary_value:.5f} | \"\n",
    "            f\"{config.secondary_metric}={secondary_value:.5f} | \"\n",
    "            f\"val_loss={val_loss:.5f} | lr={current_lr:.2e} | \"\n",
    "            f\"grad_pre={max_grad_pre_epoch:.1f} grad_post={max_grad_post_epoch:.1f}{grad_warn}\"\n",
    "        )\n",
    "\n",
    "        if should_stop:\n",
    "            best_primary_val = score_to_metric_value(config.primary_metric, stopper.best_primary_score)\n",
    "            print(\n",
    "                f\"[{model_name}] Early stopping at epoch {epoch}. \"\n",
    "                f\"best_epoch={stopper.best_epoch}, best_{config.primary_metric}={best_primary_val}\"\n",
    "            )\n",
    "            break\n",
    "\n",
    "    model_seconds = float(time.time() - model_start)\n",
    "\n",
    "    if skip_model_reason is not None:\n",
    "        return {\n",
    "            \"status\": \"skipped\",\n",
    "            \"reason\": skip_model_reason,\n",
    "            \"history\": history_local,\n",
    "            \"train_seconds\": model_seconds,\n",
    "            \"params\": count_trainable_params(model_local),\n",
    "            \"seed\": run_seed,\n",
    "        }, None\n",
    "\n",
    "    if not np.isfinite(stopper.best_primary_score):\n",
    "        raise RuntimeError(f\"[{model_name}] best_primary_score is not finite: {stopper.best_primary_score}\")\n",
    "\n",
    "    selected_epoch = validate_selection_consistency(\n",
    "        history_local[\"val_primary_score\"],\n",
    "        selected_epoch=stopper.best_epoch,\n",
    "        tie_tol=config.tie_tol,\n",
    "    )\n",
    "    if int(selected_epoch) != int(stopper.best_epoch):\n",
    "        raise RuntimeError(\n",
    "            f\"[{model_name}] selection mismatch after validation: selected={stopper.best_epoch}, expected={selected_epoch}\"\n",
    "        )\n",
    "\n",
    "    best_state_source = None\n",
    "    if stopper.best_state is not None:\n",
    "        model_local.load_state_dict(stopper.best_state)\n",
    "        best_state_source = \"memory\"\n",
    "    elif stopper.best_state_path is not None and Path(stopper.best_state_path).exists():\n",
    "        disk_state = _load_checkpoint_state(Path(stopper.best_state_path))\n",
    "        model_local.load_state_dict(disk_state)\n",
    "        best_state_source = \"disk\"\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            f\"[{model_name}] no restorable best checkpoint. last_checkpoint_error={stopper.last_checkpoint_error}\"\n",
    "        )\n",
    "\n",
    "    best_primary_metric_value = score_to_metric_value(config.primary_metric, stopper.best_primary_score)\n",
    "    print(\n",
    "        f\"[{model_name}] Loaded best checkpoint epoch={stopper.best_epoch} (source={best_state_source}), \"\n",
    "        f\"best_{config.primary_metric}={best_primary_metric_value:.6f}\"\n",
    "    )\n",
    "\n",
    "    summary = {\n",
    "        \"status\": \"ok\",\n",
    "        \"history\": history_local,\n",
    "        \"train_seconds\": model_seconds,\n",
    "        \"params\": count_trainable_params(model_local),\n",
    "        \"seed\": run_seed,\n",
    "        \"best_epoch\": int(stopper.best_epoch),\n",
    "        \"best_val_primary_score\": float(stopper.best_primary_score),\n",
    "        \"best_val_primary_metric\": float(best_primary_metric_value),\n",
    "        \"primary_metric_name\": config.primary_metric,\n",
    "        \"best_val_loss\": float(stopper.best_loss) if stopper.best_loss is not None else np.nan,\n",
    "        \"epochs_completed\": int(len(history_local[\"train_loss\"])),\n",
    "        \"best_state_source\": best_state_source,\n",
    "        \"best_state_path\": stopper.best_state_path,\n",
    "    }\n",
    "    return summary, model_local\n",
    "\n",
    "\n",
    "training_wall_start = time.time()\n",
    "deep_training_results = {}\n",
    "deep_histories = {}\n",
    "trained_models = {}\n",
    "deep_training_failures = {}\n",
    "\n",
    "for model_idx, model_name in enumerate(config.model_names):\n",
    "    try:\n",
    "        summary, trained_model = train_one_model(model_name, seed_offset=1000 * model_idx)\n",
    "        deep_training_results[model_name] = {\n",
    "            k: v for k, v in summary.items() if k != \"history\"\n",
    "        }\n",
    "        deep_histories[model_name] = summary.get(\"history\", {})\n",
    "        if summary.get(\"status\") == \"ok\" and trained_model is not None:\n",
    "            trained_models[model_name] = trained_model\n",
    "        else:\n",
    "            deep_training_failures[model_name] = summary.get(\"reason\", \"unknown\")\n",
    "    except Exception as exc:\n",
    "        deep_training_failures[model_name] = str(exc)\n",
    "        deep_training_results[model_name] = {\n",
    "            \"status\": \"failed\",\n",
    "            \"reason\": str(exc),\n",
    "        }\n",
    "        if config.nan_policy == \"fail_fast\":\n",
    "            raise\n",
    "        print(f\"WARNING: model {model_name} failed and will be skipped: {exc}\")\n",
    "\n",
    "total_train_time = float(time.time() - training_wall_start)\n",
    "\n",
    "successful_models = [\n",
    "    name for name, meta in deep_training_results.items()\n",
    "    if meta.get(\"status\") == \"ok\" and name in trained_models\n",
    "]\n",
    "if not successful_models:\n",
    "    raise RuntimeError(\n",
    "        f\"No successful deep models. Failures={deep_training_failures}\"\n",
    "    )\n",
    "\n",
    "successful_models_sorted = sorted(\n",
    "    successful_models,\n",
    "    key=lambda n: float(deep_training_results[n][\"best_val_primary_score\"]),\n",
    "    reverse=True,\n",
    ")\n",
    "best_model_name = successful_models_sorted[0]\n",
    "model = trained_models[best_model_name]\n",
    "history = deep_histories[best_model_name]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING SUMMARY (VALIDATION, TRAJECTORY-WEIGHTED)\")\n",
    "print(\"=\" * 70)\n",
    "print(\n",
    "    f\"{'Model':<14} {'Status':<8} \"\n",
    "    f\"{config.primary_metric:>18s} {'Best Ep':>8} {'Params':>12} {'Time':>10}\"\n",
    ")\n",
    "print(\"-\" * 82)\n",
    "for name in config.model_names:\n",
    "    meta = deep_training_results.get(name, {})\n",
    "    if meta.get(\"status\") == \"ok\":\n",
    "        print(\n",
    "            f\"{name:<14} {'ok':<8} \"\n",
    "            f\"{meta.get('best_val_primary_metric', np.nan):>18.6f} \"\n",
    "            f\"{meta.get('best_epoch', 0):>8d} \"\n",
    "            f\"{meta.get('params', 0):>12,} \"\n",
    "            f\"{meta.get('train_seconds', 0.0):>9.1f}s\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"{name:<14} {meta.get('status', 'failed'):<8} {'n/a':>18} {'n/a':>8} {'n/a':>12} {'n/a':>10}\")\n",
    "\n",
    "print(f\"Total training wall time: {format_time(total_train_time)}\")\n",
    "print(f\"Best validation model: {best_model_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca4d454",
   "metadata": {},
   "source": [
    "## 10. Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e43be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if not deep_histories:\n",
    "    print(\"No histories available to plot.\")\n",
    "else:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 9))\n",
    "\n",
    "    # Primary selection metric (trajectory-weighted by default)\n",
    "    for model_name, hist in deep_histories.items():\n",
    "        y = np.asarray(hist.get(\"val_primary_metric\", []), dtype=np.float64)\n",
    "        if y.size > 0:\n",
    "            axes[0, 0].plot(y, label=model_name)\n",
    "    axes[0, 0].set_title(f\"Validation Primary Metric ({config.primary_metric})\")\n",
    "    axes[0, 0].set_xlabel(\"Epoch\")\n",
    "    axes[0, 0].set_ylabel(config.primary_metric)\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].legend()\n",
    "\n",
    "    # Trajectory-weighted R2 (secondary diagnostic)\n",
    "    for model_name, hist in deep_histories.items():\n",
    "        y = np.asarray(hist.get(\"val_traj_r2_vw_orig\", []), dtype=np.float64)\n",
    "        if y.size > 0:\n",
    "            axes[0, 1].plot(y, label=model_name)\n",
    "    axes[0, 1].set_title(\"Validation Trajectory-weighted R2\")\n",
    "    axes[0, 1].set_xlabel(\"Epoch\")\n",
    "    axes[0, 1].set_ylabel(\"traj_r2_vw_orig\")\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[0, 1].legend()\n",
    "\n",
    "    # Best-model gradients\n",
    "    best_hist = deep_histories.get(best_model_name, {})\n",
    "    axes[1, 0].plot(best_hist.get(\"max_grad_pre\", []), color=\"tab:red\", label=\"pre-clip\")\n",
    "    axes[1, 0].plot(best_hist.get(\"max_grad_post\", []), color=\"tab:blue\", label=\"post-clip\")\n",
    "    axes[1, 0].axhline(y=float(config.gradient_clip), color=\"black\", linestyle=\"--\", label=f\"clip={config.gradient_clip}\")\n",
    "    axes[1, 0].set_title(f\"Gradient norms ({best_model_name})\")\n",
    "    axes[1, 0].set_xlabel(\"Epoch\")\n",
    "    axes[1, 0].set_ylabel(\"Max grad norm\")\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    axes[1, 0].legend()\n",
    "\n",
    "    # Best-model LR\n",
    "    axes[1, 1].plot(best_hist.get(\"lr_used\", []), color=\"tab:orange\", label=\"lr_used\")\n",
    "    axes[1, 1].plot(best_hist.get(\"lr_next\", []), color=\"gray\", alpha=0.7, label=\"lr_next\")\n",
    "    axes[1, 1].set_yscale(\"log\")\n",
    "    axes[1, 1].set_title(f\"LR schedule ({best_model_name})\")\n",
    "    axes[1, 1].set_xlabel(\"Epoch\")\n",
    "    axes[1, 1].set_ylabel(\"LR\")\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    axes[1, 1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572f523d",
   "metadata": {},
   "source": [
    "## 11. Final Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7901fbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"FINAL EVALUATION (DEEP MODELS)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "deep_test_results = {}\n",
    "\n",
    "eval_loss_fn = make_loss(config.loss_type)\n",
    "for model_name in trained_models.keys():\n",
    "    model_eval = trained_models[model_name]\n",
    "    test_loss, test_preds_scaled, test_targets_scaled = evaluate(\n",
    "        model_eval,\n",
    "        test_loader,\n",
    "        device,\n",
    "        eval_loss_fn,\n",
    "        desc=f\"Test-{model_name}\",\n",
    "        pred_clip=config.eval_pred_clip,\n",
    "    )\n",
    "    test_preds_orig = target_scaler.inverse_transform(test_preds_scaled)\n",
    "    test_targets_orig = target_scaler.inverse_transform(test_targets_scaled)\n",
    "\n",
    "    metrics = compute_metrics(\n",
    "        test_targets_orig,\n",
    "        test_preds_orig,\n",
    "        target_names=target_cols,\n",
    "        nan_eps=config.nan_eps,\n",
    "        scaled_pair=(test_targets_scaled, test_preds_scaled),\n",
    "    )\n",
    "    traj_metrics = compute_trajectory_weighted_metrics(\n",
    "        test_targets_orig,\n",
    "        test_preds_orig,\n",
    "        window_groups=test_window_groups,\n",
    "        target_names=target_cols,\n",
    "        nan_eps=config.nan_eps,\n",
    "        scaled_pair=(test_targets_scaled, test_preds_scaled),\n",
    "        target_scale=target_scale_iqr_orig,\n",
    "    )\n",
    "\n",
    "    deep_test_results[model_name] = {\n",
    "        \"test_loss\": float(test_loss),\n",
    "        \"metrics\": metrics,\n",
    "        \"traj_metrics\": traj_metrics,\n",
    "    }\n",
    "\n",
    "leaderboard_rows = []\n",
    "for model_name, payload in deep_test_results.items():\n",
    "    met = payload[\"metrics\"]\n",
    "    tmet = payload[\"traj_metrics\"]\n",
    "    leaderboard_rows.append(\n",
    "        {\n",
    "            \"model\": model_name,\n",
    "            \"traj_mae_orig\": float(tmet.get(\"traj_mae_orig\", np.nan)),\n",
    "            \"traj_nmae_iqr\": float(tmet.get(\"traj_nmae_iqr\", np.nan)),\n",
    "            \"traj_nmae_iqr_median_target\": float(tmet.get(\"traj_nmae_iqr_median_target\", np.nan)),\n",
    "            \"traj_rmse_orig\": float(tmet.get(\"traj_rmse_orig\", np.nan)),\n",
    "            \"traj_r2_vw_orig\": float(tmet.get(\"traj_r2_vw_orig\", np.nan)),\n",
    "            \"traj_r2_median_orig\": float(tmet.get(\"traj_r2_median_orig\", np.nan)),\n",
    "            \"r2_vw_orig\": float(met.get(\"r2_vw_orig\", np.nan)),\n",
    "            \"rmse\": float(met.get(\"rmse\", np.nan)),\n",
    "            \"mae\": float(met.get(\"mae\", np.nan)),\n",
    "            \"test_loss\": float(payload.get(\"test_loss\", np.nan)),\n",
    "        }\n",
    "    )\n",
    "\n",
    "if config.primary_metric in LOWER_IS_BETTER_METRICS:\n",
    "    leaderboard_rows.sort(\n",
    "        key=lambda row: (\n",
    "            np.inf if not np.isfinite(row.get(config.primary_metric, np.nan)) else row.get(config.primary_metric, np.nan)\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    leaderboard_rows.sort(\n",
    "        key=lambda row: (\n",
    "            -np.inf if not np.isfinite(row.get(config.primary_metric, np.nan)) else row.get(config.primary_metric, np.nan)\n",
    "        ),\n",
    "        reverse=True,\n",
    "    )\n",
    "\n",
    "print(\n",
    "    f\"{'Model':<14} {'traj_MAE':>10} {'traj_nMAE':>10} {'traj_RMSE':>10} \"\n",
    "    f\"{'traj_R2':>10} {'traj_R2_med':>12} {'global_R2':>10}\"\n",
    ")\n",
    "print(\"-\" * 80)\n",
    "for row in leaderboard_rows:\n",
    "    print(\n",
    "        f\"{row['model']:<14} \"\n",
    "        f\"{row['traj_mae_orig']:>10.4f} \"\n",
    "        f\"{row['traj_nmae_iqr']:>10.4f} \"\n",
    "        f\"{row['traj_rmse_orig']:>10.4f} \"\n",
    "        f\"{row['traj_r2_vw_orig']:>10.4f} \"\n",
    "        f\"{row['traj_r2_median_orig']:>12.4f} \"\n",
    "        f\"{row['r2_vw_orig']:>10.4f}\"\n",
    "    )\n",
    "\n",
    "if not leaderboard_rows:\n",
    "    raise RuntimeError(\"No deep test results available.\")\n",
    "\n",
    "champion_model_name = leaderboard_rows[0][\"model\"]\n",
    "champion_model = trained_models[champion_model_name]\n",
    "model = champion_model\n",
    "\n",
    "test_metrics = deep_test_results[champion_model_name][\"metrics\"]\n",
    "test_traj_metrics = deep_test_results[champion_model_name][\"traj_metrics\"]\n",
    "\n",
    "print(\"\\nChampion deep model:\", champion_model_name)\n",
    "print(f\"  Primary ({config.primary_metric}): {test_traj_metrics.get(config.primary_metric, np.nan):.4f}\")\n",
    "print(f\"  traj_nMAE_iqr:               {test_traj_metrics.get('traj_nmae_iqr', np.nan):.4f}\")\n",
    "print(f\"  traj_nMAE_iqr_med_target:    {test_traj_metrics.get('traj_nmae_iqr_median_target', np.nan):.4f}\")\n",
    "print(f\"  traj_RMSE_orig:               {test_traj_metrics['traj_rmse_orig']:.4f}\")\n",
    "print(f\"  traj_R2_vw_orig:             {test_traj_metrics['traj_r2_vw_orig']:.4f}\")\n",
    "print(f\"  traj_R2_median_orig:         {test_traj_metrics['traj_r2_median_orig']:.4f}\")\n",
    "print(f\"  global_R2_vw_orig:           {test_metrics['r2_vw_orig']:.4f}\")\n",
    "print(f\"  global_RMSE:                 {test_metrics['rmse']:.4f}\")\n",
    "print(f\"  global_MAE:                  {test_metrics['mae']:.4f}\")\n",
    "\n",
    "print(\"\\nPer-target R2 (global):\")\n",
    "for name, r2v in zip(target_cols, test_metrics[\"r2_per_target\"]):\n",
    "    status = \"OK\" if np.isfinite(r2v) and r2v > 0 else \"BAD\"\n",
    "    bar = \"#\" * int(max(0.0, float(r2v)) * 24) if np.isfinite(r2v) else \"\"\n",
    "    print(f\"  {status:>3s} {name:12s}: {float(r2v):+8.4f} {bar}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786cea93",
   "metadata": {},
   "source": [
    "## 12. XGBoost Baseline Comparison (GPU, Full Data)\n",
    "\n",
    "Train XGBoost on full training data and use GPU (`device=\"cuda\"`) for acceleration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7aa642",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"BASELINE COMPARISON (XGBOOST) - GPU FULL DATA\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Training XGBoost on full dataset (no subsampling).\")\n",
    "\n",
    "import gc\n",
    "import tempfile\n",
    "\n",
    "et_memmap_dirs = []\n",
    "\n",
    "\n",
    "def _trajectory_name(df: pd.DataFrame, default_name: str) -> str:\n",
    "    if \"trajectory\" in df.columns and len(df[\"trajectory\"]) > 0:\n",
    "        return str(df[\"trajectory\"].iloc[0])\n",
    "    return default_name\n",
    "\n",
    "\n",
    "def _clean_scaled_arrays(df, feat_cols, tgt_cols, feat_scaler, tgt_scaler):\n",
    "    df_clean = df.dropna(subset=feat_cols + tgt_cols)\n",
    "    if len(df_clean) == 0:\n",
    "        return None, None\n",
    "    x = feat_scaler.transform(df_clean[feat_cols].values).astype(np.float32, copy=False)\n",
    "    y = tgt_scaler.transform(df_clean[tgt_cols].values).astype(np.float32, copy=False)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def _count_windows(dfs, feat_cols, tgt_cols, seq_len: int, stride: int):\n",
    "    total = 0\n",
    "    per_traj = []\n",
    "    for df in dfs:\n",
    "        df_clean = df.dropna(subset=feat_cols + tgt_cols)\n",
    "        n = len(df_clean)\n",
    "        if n < seq_len:\n",
    "            per_traj.append(0)\n",
    "            continue\n",
    "        n_w = 1 + (n - seq_len) // stride\n",
    "        per_traj.append(int(n_w))\n",
    "        total += int(n_w)\n",
    "    return int(total), per_traj\n",
    "\n",
    "\n",
    "def _estimate_flat_raw_mb(n_windows: int, seq_len: int, n_feat: int, n_tgt: int):\n",
    "    x_bytes = n_windows * seq_len * n_feat * 4\n",
    "    y_bytes = n_windows * n_tgt * 4\n",
    "    g_bytes = n_windows * 4\n",
    "    return float((x_bytes + y_bytes + g_bytes) / (1024 ** 2))\n",
    "\n",
    "\n",
    "def build_endpoint_windows(\n",
    "    dfs, feat_cols, tgt_cols, feat_scaler, tgt_scaler, seq_len: int, stride: int\n",
    "):\n",
    "    x_list, y_list, g_list = [], [], []\n",
    "    traj_map = {}\n",
    "    gid = 0\n",
    "    for df_idx, df in enumerate(dfs):\n",
    "        x, y = _clean_scaled_arrays(df, feat_cols, tgt_cols, feat_scaler, tgt_scaler)\n",
    "        if x is None or len(x) < seq_len:\n",
    "            continue\n",
    "        idx = np.arange(seq_len - 1, len(x), stride, dtype=np.int64)\n",
    "        if idx.size == 0:\n",
    "            continue\n",
    "        x_list.append(x[idx])\n",
    "        y_list.append(y[idx])\n",
    "        g_list.append(np.full(idx.size, gid, dtype=np.int32))\n",
    "        traj_map[int(gid)] = _trajectory_name(df, f\"traj_{df_idx}\")\n",
    "        gid += 1\n",
    "    if not x_list:\n",
    "        return None, None, None, {}\n",
    "    return (\n",
    "        np.concatenate(x_list, axis=0),\n",
    "        np.concatenate(y_list, axis=0),\n",
    "        np.concatenate(g_list, axis=0),\n",
    "        traj_map,\n",
    "    )\n",
    "\n",
    "\n",
    "def build_flat_raw_windows(\n",
    "    dfs,\n",
    "    feat_cols,\n",
    "    tgt_cols,\n",
    "    feat_scaler,\n",
    "    tgt_scaler,\n",
    "    seq_len: int,\n",
    "    stride: int,\n",
    "    builder: str = \"auto\",\n",
    "    max_ram_mb: int = 3072,\n",
    "):\n",
    "    n_windows, per_traj = _count_windows(dfs, feat_cols, tgt_cols, seq_len=seq_len, stride=stride)\n",
    "    if n_windows <= 0:\n",
    "        return None, None, None, {}, {\"use_memmap\": False, \"estimated_mb\": 0.0, \"memmap_dir\": None}\n",
    "\n",
    "    n_feat = len(feat_cols)\n",
    "    n_tgt = len(tgt_cols)\n",
    "    estimated_mb = _estimate_flat_raw_mb(n_windows, seq_len, n_feat, n_tgt)\n",
    "\n",
    "    if builder == \"memmap\":\n",
    "        use_memmap = True\n",
    "    elif builder == \"in_memory\":\n",
    "        use_memmap = False\n",
    "    else:\n",
    "        use_memmap = bool(estimated_mb > float(max_ram_mb))\n",
    "\n",
    "    if use_memmap:\n",
    "        mm_dir = Path(tempfile.mkdtemp(prefix=\"et_flat_raw_\"))\n",
    "        et_memmap_dirs.append(mm_dir)\n",
    "        X = np.memmap(mm_dir / \"X.dat\", dtype=np.float32, mode=\"w+\", shape=(n_windows, seq_len * n_feat))\n",
    "        y = np.memmap(mm_dir / \"y.dat\", dtype=np.float32, mode=\"w+\", shape=(n_windows, n_tgt))\n",
    "        g = np.memmap(mm_dir / \"g.dat\", dtype=np.int32, mode=\"w+\", shape=(n_windows,))\n",
    "    else:\n",
    "        mm_dir = None\n",
    "        X = np.empty((n_windows, seq_len * n_feat), dtype=np.float32)\n",
    "        y = np.empty((n_windows, n_tgt), dtype=np.float32)\n",
    "        g = np.empty((n_windows,), dtype=np.int32)\n",
    "\n",
    "    write_idx = 0\n",
    "    gid = 0\n",
    "    traj_map = {}\n",
    "    for df_idx, df in enumerate(dfs):\n",
    "        x_sc, y_sc = _clean_scaled_arrays(df, feat_cols, tgt_cols, feat_scaler, tgt_scaler)\n",
    "        if x_sc is None or len(x_sc) < seq_len:\n",
    "            continue\n",
    "        traj_map[int(gid)] = _trajectory_name(df, f\"traj_{df_idx}\")\n",
    "        for start in range(0, len(x_sc) - seq_len + 1, stride):\n",
    "            end = start + seq_len\n",
    "            X[write_idx] = x_sc[start:end].reshape(-1)\n",
    "            y[write_idx] = y_sc[end - 1]\n",
    "            g[write_idx] = gid\n",
    "            write_idx += 1\n",
    "        gid += 1\n",
    "\n",
    "    if write_idx != n_windows:\n",
    "        X = X[:write_idx]\n",
    "        y = y[:write_idx]\n",
    "        g = g[:write_idx]\n",
    "        n_windows = write_idx\n",
    "\n",
    "    meta = {\n",
    "        \"use_memmap\": bool(use_memmap),\n",
    "        \"estimated_mb\": float(estimated_mb),\n",
    "        \"memmap_dir\": str(mm_dir) if mm_dir is not None else None,\n",
    "    }\n",
    "    return X, y, g, traj_map, meta\n",
    "\n",
    "\n",
    "def build_flat_stats_windows(\n",
    "    dfs, feat_cols, tgt_cols, feat_scaler, tgt_scaler, seq_len: int, stride: int\n",
    "):\n",
    "    x_list, y_list, g_list = [], [], []\n",
    "    traj_map = {}\n",
    "    gid = 0\n",
    "    for df_idx, df in enumerate(dfs):\n",
    "        x_sc, y_sc = _clean_scaled_arrays(df, feat_cols, tgt_cols, feat_scaler, tgt_scaler)\n",
    "        if x_sc is None or len(x_sc) < seq_len:\n",
    "            continue\n",
    "        traj_map[int(gid)] = _trajectory_name(df, f\"traj_{df_idx}\")\n",
    "        feats = []\n",
    "        targets = []\n",
    "        for start in range(0, len(x_sc) - seq_len + 1, stride):\n",
    "            end = start + seq_len\n",
    "            w = x_sc[start:end]\n",
    "            feat = np.concatenate(\n",
    "                [\n",
    "                    w[-1],\n",
    "                    w.mean(axis=0),\n",
    "                    w.std(axis=0),\n",
    "                    w.min(axis=0),\n",
    "                    w.max(axis=0),\n",
    "                    (w[-1] - w[0]),\n",
    "                ]\n",
    "            ).astype(np.float32, copy=False)\n",
    "            feats.append(feat)\n",
    "            targets.append(y_sc[end - 1])\n",
    "        if feats:\n",
    "            x_list.append(np.vstack(feats))\n",
    "            y_list.append(np.vstack(targets).astype(np.float32, copy=False))\n",
    "            g_list.append(np.full(len(feats), gid, dtype=np.int32))\n",
    "            gid += 1\n",
    "    if not x_list:\n",
    "        return None, None, None, {}\n",
    "    return (\n",
    "        np.concatenate(x_list, axis=0),\n",
    "        np.concatenate(y_list, axis=0),\n",
    "        np.concatenate(g_list, axis=0),\n",
    "        traj_map,\n",
    "    )\n",
    "\n",
    "\n",
    "def _group_subsample(X, y, groups, max_samples: int, rng: np.random.RandomState):\n",
    "    if X is None:\n",
    "        return None, None, None\n",
    "    n = len(X)\n",
    "    max_samples = int(max_samples)\n",
    "    if max_samples <= 0 or n <= max_samples:\n",
    "        return X, y, groups\n",
    "    if groups is None:\n",
    "        idx = rng.choice(n, size=max_samples, replace=False)\n",
    "        return X[idx], y[idx], None\n",
    "\n",
    "    groups = np.asarray(groups)\n",
    "    uniq = np.unique(groups)\n",
    "    selected = []\n",
    "    for gid in uniq:\n",
    "        idx = np.flatnonzero(groups == gid)\n",
    "        if idx.size > 0:\n",
    "            selected.append(int(rng.choice(idx)))\n",
    "    selected = np.asarray(sorted(set(selected)), dtype=np.int64)\n",
    "    budget = max_samples - selected.size\n",
    "    if budget > 0:\n",
    "        remaining = np.setdiff1d(np.arange(n), selected, assume_unique=False)\n",
    "        if remaining.size > budget:\n",
    "            extra = rng.choice(remaining, size=budget, replace=False)\n",
    "        else:\n",
    "            extra = remaining\n",
    "        selected = np.concatenate([selected, extra.astype(np.int64)])\n",
    "    if selected.size > max_samples:\n",
    "        selected = selected[:max_samples]\n",
    "    rng.shuffle(selected)\n",
    "    return X[selected], y[selected], groups[selected]\n",
    "\n",
    "\n",
    "def _build_xgb_base(random_state: int, device: str):\n",
    "    return XGBRegressor(\n",
    "        n_estimators=int(config.xgb_n_estimators),\n",
    "        max_depth=int(config.xgb_max_depth),\n",
    "        learning_rate=float(config.xgb_learning_rate),\n",
    "        subsample=float(config.xgb_subsample),\n",
    "        colsample_bytree=float(config.xgb_colsample_bytree),\n",
    "        reg_alpha=float(config.xgb_reg_alpha),\n",
    "        reg_lambda=float(config.xgb_reg_lambda),\n",
    "        objective=\"reg:squarederror\",\n",
    "        tree_method=\"hist\",\n",
    "        device=device,\n",
    "        random_state=int(random_state),\n",
    "        n_jobs=int(config.xgb_n_jobs_cpu if device == \"cpu\" else 1),\n",
    "        verbosity=1,\n",
    "    )\n",
    "\n",
    "\n",
    "def _fit_et(X_train, y_train, random_state: int):\n",
    "    y_arr = np.asarray(y_train)\n",
    "    prefer_cuda = bool(torch.cuda.is_available()) and str(config.xgb_device).lower() == \"cuda\"\n",
    "    requested_device = \"cuda\" if prefer_cuda else \"cpu\"\n",
    "\n",
    "    def _fit_with_device(dev: str):\n",
    "        base = _build_xgb_base(random_state=int(random_state), device=dev)\n",
    "        if y_arr.ndim == 1 or (y_arr.ndim == 2 and y_arr.shape[1] == 1):\n",
    "            model_local = base\n",
    "        else:\n",
    "            model_local = MultiOutputRegressor(base, n_jobs=1)\n",
    "        t0 = time.time()\n",
    "        model_local.fit(X_train, y_arr)\n",
    "        train_seconds = float(time.time() - t0)\n",
    "        return model_local, train_seconds, dev\n",
    "\n",
    "    try:\n",
    "        model_local, train_seconds, used_device = _fit_with_device(requested_device)\n",
    "    except Exception as exc:\n",
    "        if requested_device == \"cuda\":\n",
    "            print(f\"  XGBoost GPU failed ({exc}); retrying on CPU.\")\n",
    "            model_local, train_seconds, used_device = _fit_with_device(\"cpu\")\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    print(f\"  XGBoost device={used_device}\")\n",
    "    return model_local, train_seconds\n",
    "\n",
    "\n",
    "def _evaluate_et_predictions(y_true_scaled, y_pred_scaled):\n",
    "    y_true_orig = target_scaler.inverse_transform(np.asarray(y_true_scaled, dtype=np.float64))\n",
    "    y_pred_orig = target_scaler.inverse_transform(np.asarray(y_pred_scaled, dtype=np.float64))\n",
    "    return compute_metrics(\n",
    "        y_true_orig,\n",
    "        y_pred_orig,\n",
    "        target_names=target_cols,\n",
    "        nan_eps=config.nan_eps,\n",
    "        scaled_pair=(y_true_scaled, y_pred_scaled),\n",
    "    )\n",
    "\n",
    "\n",
    "def _run_shuffle_trials(name: str, X_train, y_train, X_eval, y_eval, n_trials: int, seed: int):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    trial_scores = []\n",
    "    for trial in range(int(n_trials)):\n",
    "        perm = rng.permutation(len(y_train))\n",
    "        y_shuf = y_train[perm]\n",
    "        m, _ = _fit_et(X_train, y_shuf, random_state=seed + 17 * (trial + 1))\n",
    "        pred = m.predict(X_eval)\n",
    "        met = _evaluate_et_predictions(y_eval, pred)\n",
    "        trial_scores.append(float(met[\"r2_vw_orig\"]))\n",
    "    arr = np.asarray(trial_scores, dtype=np.float64)\n",
    "    mean = float(np.nanmean(arr)) if arr.size > 0 else np.nan\n",
    "    std = float(np.nanstd(arr)) if arr.size > 0 else np.nan\n",
    "    return {\n",
    "        \"trial_scores\": arr.tolist(),\n",
    "        \"mean\": mean,\n",
    "        \"std\": std,\n",
    "    }\n",
    "\n",
    "\n",
    "def _run_group_kfold(name: str, X, y, groups, max_samples: int, seed: int):\n",
    "    uniq_groups = np.unique(groups) if groups is not None else np.array([])\n",
    "    n_groups = int(len(uniq_groups))\n",
    "    n_splits = min(int(config.et_cv_splits), n_groups)\n",
    "    if n_splits < 2:\n",
    "        return None\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    rng = np.random.RandomState(seed)\n",
    "    fold_scores = []\n",
    "    fold_scores_median = []\n",
    "    for fold_idx, (tr_idx, te_idx) in enumerate(gkf.split(X, y, groups=groups), start=1):\n",
    "        X_tr, y_tr, g_tr = X[tr_idx], y[tr_idx], groups[tr_idx]\n",
    "        X_te, y_te = X[te_idx], y[te_idx]\n",
    "        X_tr_s, y_tr_s, g_tr_s = _group_subsample(X_tr, y_tr, g_tr, max_samples=max_samples, rng=rng)\n",
    "        m, _ = _fit_et(X_tr_s, y_tr_s, random_state=seed + fold_idx * 101)\n",
    "        pred = m.predict(X_te)\n",
    "        met = _evaluate_et_predictions(y_te, pred)\n",
    "        fold_scores.append(float(met[\"r2_vw_orig\"]))\n",
    "        fold_scores_median.append(float(met[\"r2_median_orig\"]))\n",
    "    arr = np.asarray(fold_scores, dtype=np.float64)\n",
    "    arr_med = np.asarray(fold_scores_median, dtype=np.float64)\n",
    "    return {\n",
    "        \"n_splits\": int(n_splits),\n",
    "        \"r2_vw_orig_mean\": float(np.nanmean(arr)),\n",
    "        \"r2_vw_orig_std\": float(np.nanstd(arr)),\n",
    "        \"r2_median_orig_mean\": float(np.nanmean(arr_med)),\n",
    "        \"r2_median_orig_std\": float(np.nanstd(arr_med)),\n",
    "        \"fold_scores\": arr.tolist(),\n",
    "        \"fold_scores_median\": arr_med.tolist(),\n",
    "    }\n",
    "\n",
    "\n",
    "def _et_alignment_contract():\n",
    "    seq_len = 4\n",
    "    stride = 2\n",
    "    n = 14\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"feat\": np.arange(n, dtype=np.float64),\n",
    "            \"target\": np.arange(n, dtype=np.float64),\n",
    "            \"trajectory\": [\"synthetic_et\"] * n,\n",
    "        }\n",
    "    )\n",
    "    fs = RobustScaler().fit(df[[\"feat\"]].values)\n",
    "    ts = PerTargetScaler().fit(df[[\"target\"]].values, [\"target\"])\n",
    "\n",
    "    x_end, y_end, g_end, _ = build_endpoint_windows([df], [\"feat\"], [\"target\"], fs, ts, seq_len=seq_len, stride=stride)\n",
    "    expected = np.arange(seq_len - 1, n, stride)\n",
    "    observed_end = np.round(ts.inverse_transform(y_end)[:, 0]).astype(np.int64)\n",
    "    if not np.array_equal(expected, observed_end):\n",
    "        raise RuntimeError(f\"ET endpoint alignment failed: expected={expected.tolist()} observed={observed_end.tolist()}\")\n",
    "\n",
    "    x_raw, y_raw, g_raw, _, _ = build_flat_raw_windows(\n",
    "        [df], [\"feat\"], [\"target\"], fs, ts, seq_len=seq_len, stride=stride, builder=\"in_memory\", max_ram_mb=config.et_max_ram_mb\n",
    "    )\n",
    "    observed_raw = np.round(ts.inverse_transform(y_raw)[:, 0]).astype(np.int64)\n",
    "    if not np.array_equal(expected, observed_raw):\n",
    "        raise RuntimeError(f\"ET flat_raw alignment failed: expected={expected.tolist()} observed={observed_raw.tolist()}\")\n",
    "\n",
    "    print(\"ET alignment contracts: PASS\")\n",
    "\n",
    "\n",
    "if config.run_contract_checks:\n",
    "    _et_alignment_contract()\n",
    "\n",
    "rng = np.random.RandomState(config.seed + 202)\n",
    "et_benchmark_results = {}\n",
    "\n",
    "X_train_end, y_train_end, g_train_end, train_traj_map_end = build_endpoint_windows(\n",
    "    train_dfs, feature_cols, target_cols, feature_scaler, target_scaler, seq_len=config.seq_len, stride=config.train_stride\n",
    ")\n",
    "X_test_end, y_test_end, g_test_end, test_traj_map_end = build_endpoint_windows(\n",
    "    test_dfs, feature_cols, target_cols, feature_scaler, target_scaler, seq_len=config.seq_len, stride=config.eval_stride\n",
    ")\n",
    "\n",
    "X_train_raw, y_train_raw, g_train_raw, train_traj_map_raw, raw_meta = build_flat_raw_windows(\n",
    "    train_dfs,\n",
    "    feature_cols,\n",
    "    target_cols,\n",
    "    feature_scaler,\n",
    "    target_scaler,\n",
    "    seq_len=config.seq_len,\n",
    "    stride=config.train_stride,\n",
    "    builder=config.et_builder,\n",
    "    max_ram_mb=config.et_max_ram_mb,\n",
    ")\n",
    "X_test_raw, y_test_raw, g_test_raw, test_traj_map_raw, _ = build_flat_raw_windows(\n",
    "    test_dfs,\n",
    "    feature_cols,\n",
    "    target_cols,\n",
    "    feature_scaler,\n",
    "    target_scaler,\n",
    "    seq_len=config.seq_len,\n",
    "    stride=config.eval_stride,\n",
    "    builder=config.et_builder,\n",
    "    max_ram_mb=config.et_max_ram_mb,\n",
    ")\n",
    "\n",
    "X_train_stats, y_train_stats, g_train_stats, train_traj_map_stats = build_flat_stats_windows(\n",
    "    train_dfs, feature_cols, target_cols, feature_scaler, target_scaler, seq_len=config.seq_len, stride=config.train_stride\n",
    ")\n",
    "X_test_stats, y_test_stats, g_test_stats, test_traj_map_stats = build_flat_stats_windows(\n",
    "    test_dfs, feature_cols, target_cols, feature_scaler, target_scaler, seq_len=config.seq_len, stride=config.eval_stride\n",
    ")\n",
    "\n",
    "if g_train_end is not None:\n",
    "    assert len(np.unique(g_train_end)) == len(train_traj_map_end), \"group mapping mismatch for endpoints\"\n",
    "if g_train_raw is not None:\n",
    "    assert len(np.unique(g_train_raw)) == len(train_traj_map_raw), \"group mapping mismatch for flat_raw\"\n",
    "if g_train_stats is not None:\n",
    "    assert len(np.unique(g_train_stats)) == len(train_traj_map_stats), \"group mapping mismatch for flat_stats\"\n",
    "\n",
    "print(f\"ET flat_raw builder meta: {raw_meta}\")\n",
    "\n",
    "\n",
    "def run_et_baseline(\n",
    "    name: str,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    g_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    parity_valid: bool,\n",
    "    shuffle_trials: int,\n",
    "    seed_offset: int,\n",
    "):\n",
    "    if X_train is None or y_train is None or X_test is None or y_test is None:\n",
    "        return {\"status\": \"skipped\", \"reason\": \"no windows\"}\n",
    "    if len(X_train) == 0 or len(X_test) == 0:\n",
    "        return {\"status\": \"skipped\", \"reason\": \"empty windows\"}\n",
    "\n",
    "    X_tr, y_tr, g_tr = _group_subsample(\n",
    "        X_train, y_train, g_train, max_samples=config.et_max_samples, rng=np.random.RandomState(config.seed + seed_offset)\n",
    "    )\n",
    "    print(f\"  n_train_total={int(len(X_train)):,}  n_train_used={int(len(X_tr)):,}  n_test={int(len(X_test)):,}\")\n",
    "    model_et, train_time = _fit_et(X_tr, y_tr, random_state=config.seed + seed_offset)\n",
    "    pred_test = model_et.predict(X_test)\n",
    "    real_metrics = _evaluate_et_predictions(y_test, pred_test)\n",
    "\n",
    "    cv = _run_group_kfold(\n",
    "        name=name,\n",
    "        X=X_train,\n",
    "        y=y_train,\n",
    "        groups=g_train,\n",
    "        max_samples=config.et_max_samples,\n",
    "        seed=config.seed + seed_offset + 1,\n",
    "    )\n",
    "\n",
    "    shuffle = _run_shuffle_trials(\n",
    "        name=name,\n",
    "        X_train=X_tr,\n",
    "        y_train=y_tr,\n",
    "        X_eval=X_test,\n",
    "        y_eval=y_test,\n",
    "        n_trials=shuffle_trials,\n",
    "        seed=config.seed + seed_offset + 11,\n",
    "    )\n",
    "    std = float(shuffle[\"std\"]) if np.isfinite(shuffle[\"std\"]) else np.nan\n",
    "    if np.isfinite(std) and std > 0:\n",
    "        z_score = (float(real_metrics[\"r2_vw_orig\"]) - float(shuffle[\"mean\"])) / std\n",
    "    else:\n",
    "        z_score = np.nan\n",
    "\n",
    "    evidence = {\n",
    "        \"warn_shuffle_high\": bool(np.isfinite(shuffle[\"mean\"]) and shuffle[\"mean\"] > config.et_warn_shuffle_r2),\n",
    "        \"fail_shuffle_high\": bool(np.isfinite(shuffle[\"mean\"]) and shuffle[\"mean\"] > config.et_fail_shuffle_r2),\n",
    "        \"warn_low_zscore\": bool(np.isfinite(z_score) and z_score < config.et_zscore_warn),\n",
    "        \"z_score\": float(z_score) if np.isfinite(z_score) else np.nan,\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"status\": \"ok\",\n",
    "        \"parity_valid\": bool(parity_valid),\n",
    "        \"n_train_total\": int(len(X_train)),\n",
    "        \"n_train_used\": int(len(X_tr)),\n",
    "        \"n_test\": int(len(X_test)),\n",
    "        \"n_features\": int(X_train.shape[1]),\n",
    "        \"train_time_seconds\": float(train_time),\n",
    "        \"metrics\": real_metrics,\n",
    "        \"shuffle\": shuffle,\n",
    "        \"cv\": cv,\n",
    "        \"evidence\": evidence,\n",
    "    }\n",
    "\n",
    "\n",
    "baseline_specs = [\n",
    "    (\"XGB_endpoints\", X_train_end, y_train_end, g_train_end, X_test_end, y_test_end, False, int(config.et_shuffle_trials_endpoints), 100),\n",
    "    (\"XGB_flat_raw\", X_train_raw, y_train_raw, g_train_raw, X_test_raw, y_test_raw, True, int(config.et_shuffle_trials_flat_raw), 200),\n",
    "    (\"XGB_flat_stats\", X_train_stats, y_train_stats, g_train_stats, X_test_stats, y_test_stats, True, int(config.et_shuffle_trials_flat_stats), 300),\n",
    "]\n",
    "\n",
    "for spec in baseline_specs:\n",
    "    name = spec[0]\n",
    "    print(f\"\\nRunning {name} ...\")\n",
    "    result = run_et_baseline(*spec)\n",
    "    et_benchmark_results[name] = result\n",
    "    if result.get(\"status\") == \"ok\":\n",
    "        met = result[\"metrics\"]\n",
    "        sh = result[\"shuffle\"]\n",
    "        ev = result[\"evidence\"]\n",
    "        print(\n",
    "            f\"  R2_vw_orig={met['r2_vw_orig']:.5f}  \"\n",
    "            f\"R2_median={met['r2_median_orig']:.5f}  \"\n",
    "            f\"RMSE={met['rmse']:.4f}  MAE={met['mae']:.4f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"  shuffle_mean={sh['mean']:.5f} shuffle_std={sh['std']:.5f} \"\n",
    "            f\"z={ev['z_score']:.3f} parity_valid={result['parity_valid']}\"\n",
    "        )\n",
    "        if ev[\"fail_shuffle_high\"]:\n",
    "            print(\"  EVIDENCE FAIL: shuffle baseline unexpectedly high.\")\n",
    "        elif ev[\"warn_shuffle_high\"] or ev[\"warn_low_zscore\"]:\n",
    "            print(\"  EVIDENCE WARN: investigate potential leakage or weak separation.\")\n",
    "    else:\n",
    "        print(f\"  skipped: {result.get('reason')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DEEP vs XGBOOST COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Champion deep model: {champion_model_name}\")\n",
    "if champion_model_name in deep_test_results:\n",
    "    deep_m = deep_test_results[champion_model_name][\"metrics\"]\n",
    "    deep_tm = deep_test_results[champion_model_name].get(\"traj_metrics\", {})\n",
    "    print(\n",
    "        f\"  Deep {champion_model_name}: traj_MAE={deep_tm.get('traj_mae_orig', np.nan):.5f} \"\n",
    "        f\"traj_nMAE={deep_tm.get('traj_nmae_iqr', np.nan):.5f} \"\n",
    "        f\"traj_R2={deep_tm.get('traj_r2_vw_orig', np.nan):.5f} \"\n",
    "        f\"global_R2={deep_m['r2_vw_orig']:.5f} RMSE={deep_m['rmse']:.4f} MAE={deep_m['mae']:.4f}\"\n",
    "    )\n",
    "\n",
    "for et_name, res in et_benchmark_results.items():\n",
    "    if res.get(\"status\") != \"ok\":\n",
    "        continue\n",
    "    m = res[\"metrics\"]\n",
    "    print(\n",
    "        f\"  {et_name:<14} R2_vw_orig={m['r2_vw_orig']:.5f} \"\n",
    "        f\"R2_median={m['r2_median_orig']:.5f} parity_valid={res.get('parity_valid')}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f771906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"PHYSICS-INFORMED RESIDUAL HYBRID + ACADEMIC FIGURES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def _col_or_zeros(df: pd.DataFrame, col: str) -> np.ndarray:\n",
    "    if col in df.columns:\n",
    "        arr = pd.to_numeric(df[col], errors=\"coerce\").to_numpy(dtype=np.float64, copy=False)\n",
    "    else:\n",
    "        arr = np.zeros(len(df), dtype=np.float64)\n",
    "    arr = np.where(np.isfinite(arr), arr, 0.0)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def build_physics_proxy_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    n = len(df)\n",
    "    if n == 0:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    feat = {}\n",
    "    feat[\"bias\"] = np.ones(n, dtype=np.float64)\n",
    "\n",
    "    if \"t_s_base\" in df.columns:\n",
    "        t = pd.to_numeric(df[\"t_s_base\"], errors=\"coerce\").to_numpy(dtype=np.float64, copy=False)\n",
    "    else:\n",
    "        t = np.arange(n, dtype=np.float64)\n",
    "    dt = np.diff(t)\n",
    "    dt = dt[np.isfinite(dt) & (dt > 0)]\n",
    "    dt_ref = float(np.median(dt)) if dt.size > 0 else 0.004\n",
    "    dt_ref = max(dt_ref, 1e-6)\n",
    "\n",
    "    sum_abs_vel = np.zeros(n, dtype=np.float64)\n",
    "    sum_abs_acc = np.zeros(n, dtype=np.float64)\n",
    "\n",
    "    for i in range(1, 7):\n",
    "        q = _col_or_zeros(df, f\"js_joint_{i}_pos\")\n",
    "        dq = _col_or_zeros(df, f\"js_joint_{i}_vel\")\n",
    "\n",
    "        if f\"js_joint_{i}_pos_d2\" in df.columns:\n",
    "            ddq = _col_or_zeros(df, f\"js_joint_{i}_pos_d2\")\n",
    "        else:\n",
    "            ddq = np.zeros_like(dq)\n",
    "            if n > 1:\n",
    "                ddq[1:] = (dq[1:] - dq[:-1]) / dt_ref\n",
    "                ddq[0] = ddq[1]\n",
    "\n",
    "        sum_abs_vel += np.abs(dq)\n",
    "        sum_abs_acc += np.abs(ddq)\n",
    "\n",
    "        feat[f\"sin_q{i}\"] = np.sin(q)\n",
    "        feat[f\"cos_q{i}\"] = np.cos(q)\n",
    "        feat[f\"sin2_q{i}\"] = np.sin(2.0 * q)\n",
    "        feat[f\"cos2_q{i}\"] = np.cos(2.0 * q)\n",
    "\n",
    "        feat[f\"dq_{i}\"] = dq\n",
    "        feat[f\"abs_dq_{i}\"] = np.abs(dq)\n",
    "        feat[f\"sign_dq_{i}\"] = np.sign(dq)\n",
    "        feat[f\"dq2_{i}\"] = dq * dq\n",
    "        feat[f\"dq_absdq_{i}\"] = dq * np.abs(dq)\n",
    "\n",
    "        feat[f\"ddq_{i}\"] = ddq\n",
    "        feat[f\"abs_ddq_{i}\"] = np.abs(ddq)\n",
    "        feat[f\"sinq_ddq_{i}\"] = np.sin(q) * ddq\n",
    "        feat[f\"cosq_ddq_{i}\"] = np.cos(q) * ddq\n",
    "\n",
    "    feat[\"sum_abs_vel\"] = sum_abs_vel\n",
    "    feat[\"sum_abs_acc\"] = sum_abs_acc\n",
    "    feat[\"sum_abs_vel2\"] = sum_abs_vel * sum_abs_vel\n",
    "\n",
    "    # Lightweight cross-joint couplings for coupled dynamics.\n",
    "    for i in range(1, 7):\n",
    "        qi = _col_or_zeros(df, f\"js_joint_{i}_pos\")\n",
    "        for j in range(i + 1, 7):\n",
    "            qj = _col_or_zeros(df, f\"js_joint_{j}_pos\")\n",
    "            feat[f\"sin_q{i}_q{j}\"] = np.sin(qi - qj)\n",
    "            feat[f\"cos_q{i}_q{j}\"] = np.cos(qi - qj)\n",
    "\n",
    "    X = pd.DataFrame(feat, index=df.index)\n",
    "    X = X.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "    return X\n",
    "\n",
    "\n",
    "def extract_endpoint_values(\n",
    "    dfs,\n",
    "    value_cols,\n",
    "    dropna_cols,\n",
    "    seq_len: int,\n",
    "    stride: int,\n",
    "):\n",
    "    arrs = []\n",
    "    groups = []\n",
    "    traj_map = {}\n",
    "    gid = 0\n",
    "\n",
    "    for df_idx, df in enumerate(dfs):\n",
    "        if not all(c in df.columns for c in value_cols):\n",
    "            continue\n",
    "\n",
    "        req = [c for c in dropna_cols if c in df.columns]\n",
    "        req += list(value_cols)\n",
    "        req = list(dict.fromkeys(req))\n",
    "\n",
    "        d = df.dropna(subset=req)\n",
    "        n = len(d)\n",
    "        if n < seq_len:\n",
    "            continue\n",
    "\n",
    "        idx = np.arange(seq_len - 1, n, stride, dtype=np.int64)\n",
    "        if idx.size == 0:\n",
    "            continue\n",
    "\n",
    "        arrs.append(d[value_cols].to_numpy(dtype=np.float64, copy=False)[idx])\n",
    "        groups.append(np.full(idx.size, gid, dtype=np.int32))\n",
    "        if \"trajectory\" in d.columns and len(d[\"trajectory\"]) > 0:\n",
    "            traj_map[int(gid)] = str(d[\"trajectory\"].iloc[0])\n",
    "        else:\n",
    "            traj_map[int(gid)] = f\"traj_{df_idx}\"\n",
    "        gid += 1\n",
    "\n",
    "    if not arrs:\n",
    "        return np.empty((0, len(value_cols)), dtype=np.float64), np.empty((0,), dtype=np.int32), {}\n",
    "\n",
    "    return np.concatenate(arrs, axis=0), np.concatenate(groups, axis=0), traj_map\n",
    "\n",
    "\n",
    "hybrid_results = {}\n",
    "paper_figure_paths = {}\n",
    "comparison_rows_extended = []\n",
    "\n",
    "if not bool(getattr(config, \"run_physics_hybrid\", True)):\n",
    "    print(\"run_physics_hybrid=False; skipping hybrid section.\")\n",
    "else:\n",
    "    print(\"\\n[1/5] Fitting physics-proxy branch (gravity/inertia/friction priors) ...\")\n",
    "\n",
    "    X_parts, y_parts = [], []\n",
    "    for df in train_dfs:\n",
    "        if not all(c in df.columns for c in target_cols):\n",
    "            continue\n",
    "        d = df.dropna(subset=target_cols)\n",
    "        if len(d) == 0:\n",
    "            continue\n",
    "        X_parts.append(build_physics_proxy_features(d))\n",
    "        y_parts.append(d[target_cols].to_numpy(dtype=np.float64, copy=False))\n",
    "\n",
    "    if not X_parts:\n",
    "        raise RuntimeError(\"No valid training rows for physics-proxy fit.\")\n",
    "\n",
    "    X_phys_train = pd.concat(X_parts, axis=0, ignore_index=True).to_numpy(dtype=np.float64, copy=False)\n",
    "    y_phys_train = np.concatenate(y_parts, axis=0).astype(np.float64, copy=False)\n",
    "\n",
    "    physics_model = make_pipeline(\n",
    "        StandardScaler(with_mean=True, with_std=True),\n",
    "        Ridge(alpha=float(getattr(config, \"physics_alpha\", 2.0))),\n",
    "    )\n",
    "    physics_model.fit(X_phys_train, y_phys_train)\n",
    "    print(f\"Physics-proxy fitted on {len(X_phys_train):,} rows, {X_phys_train.shape[1]} features\")\n",
    "\n",
    "    physics_cols = [f\"phys_{t}\" for t in target_cols]\n",
    "    residual_target_cols = [f\"resid_{t}\" for t in target_cols]\n",
    "\n",
    "    def attach_physics_and_residual(dfs):\n",
    "        out = []\n",
    "        for df in dfs:\n",
    "            d = df.copy()\n",
    "            if len(d) == 0:\n",
    "                out.append(d)\n",
    "                continue\n",
    "            Xd = build_physics_proxy_features(d).to_numpy(dtype=np.float64, copy=False)\n",
    "            yhat = physics_model.predict(Xd).astype(np.float64, copy=False)\n",
    "            for j, t in enumerate(target_cols):\n",
    "                pcol = physics_cols[j]\n",
    "                rcol = residual_target_cols[j]\n",
    "                d[pcol] = yhat[:, j]\n",
    "                if t in d.columns:\n",
    "                    d[rcol] = pd.to_numeric(d[t], errors=\"coerce\") - d[pcol]\n",
    "                else:\n",
    "                    d[rcol] = np.nan\n",
    "            out.append(d)\n",
    "        return out\n",
    "\n",
    "    train_hybrid_dfs = attach_physics_and_residual(train_dfs)\n",
    "    val_hybrid_dfs = attach_physics_and_residual(val_dfs)\n",
    "    test_hybrid_dfs = attach_physics_and_residual(test_dfs)\n",
    "\n",
    "    print(\"\\n[2/5] Physics-only evaluation (endpoint windows) ...\")\n",
    "    y_true_phys, g_phys, _ = extract_endpoint_values(\n",
    "        test_hybrid_dfs,\n",
    "        value_cols=target_cols,\n",
    "        dropna_cols=feature_cols + target_cols,\n",
    "        seq_len=config.seq_len,\n",
    "        stride=config.eval_stride,\n",
    "    )\n",
    "    y_phys_pred, g_phys_pred, _ = extract_endpoint_values(\n",
    "        test_hybrid_dfs,\n",
    "        value_cols=physics_cols,\n",
    "        dropna_cols=feature_cols + target_cols,\n",
    "        seq_len=config.seq_len,\n",
    "        stride=config.eval_stride,\n",
    "    )\n",
    "\n",
    "    n_phys = min(len(y_true_phys), len(y_phys_pred))\n",
    "    y_true_phys = y_true_phys[:n_phys]\n",
    "    y_phys_pred = y_phys_pred[:n_phys]\n",
    "    g_phys = g_phys[:n_phys] if len(g_phys) >= n_phys else np.arange(n_phys, dtype=np.int32)\n",
    "\n",
    "    physics_metrics = compute_metrics(\n",
    "        y_true_phys,\n",
    "        y_phys_pred,\n",
    "        target_names=target_cols,\n",
    "        nan_eps=config.nan_eps,\n",
    "        scaled_pair=None,\n",
    "    )\n",
    "    physics_traj_metrics = compute_trajectory_weighted_metrics(\n",
    "        y_true_phys,\n",
    "        y_phys_pred,\n",
    "        window_groups=g_phys,\n",
    "        target_names=target_cols,\n",
    "        nan_eps=config.nan_eps,\n",
    "        scaled_pair=None,\n",
    "        target_scale=target_scale_iqr_orig,\n",
    "    )\n",
    "\n",
    "    print(f\"Physics-only global_R2_vw_orig={physics_metrics['r2_vw_orig']:.4f}  RMSE={physics_metrics['rmse']:.4f}  MAE={physics_metrics['mae']:.4f}\")\n",
    "\n",
    "    print(\"\\n[3/5] Building residual datasets (target = measured - physics) ...\")\n",
    "    hybrid_train_combined = pd.concat(train_hybrid_dfs, ignore_index=True)\n",
    "    hybrid_train_clean = hybrid_train_combined.dropna(subset=feature_cols + residual_target_cols)\n",
    "\n",
    "    residual_scaler = PerTargetScaler().fit(\n",
    "        hybrid_train_clean[residual_target_cols].to_numpy(dtype=np.float64, copy=False),\n",
    "        residual_target_cols,\n",
    "    )\n",
    "\n",
    "    resid_train_orig = hybrid_train_clean[residual_target_cols].to_numpy(dtype=np.float64, copy=False)\n",
    "    resid_q25 = np.nanpercentile(resid_train_orig, 25.0, axis=0)\n",
    "    resid_q75 = np.nanpercentile(resid_train_orig, 75.0, axis=0)\n",
    "    resid_iqr = np.asarray(resid_q75 - resid_q25, dtype=np.float64)\n",
    "    resid_std = np.nanstd(resid_train_orig, axis=0)\n",
    "    eps_scale = float(max(config.nan_eps, 1e-12))\n",
    "    use_std = (~np.isfinite(resid_iqr)) | (resid_iqr <= eps_scale)\n",
    "    resid_iqr[use_std] = resid_std[use_std]\n",
    "    resid_iqr = np.where(np.isfinite(resid_iqr) & (resid_iqr > eps_scale), resid_iqr, eps_scale)\n",
    "\n",
    "    del resid_train_orig, resid_q25, resid_q75, resid_std, use_std, hybrid_train_combined, hybrid_train_clean\n",
    "\n",
    "    hy_train_ds, hy_val_ds, hy_test_ds = create_trajectory_datasets(\n",
    "        train_hybrid_dfs,\n",
    "        val_hybrid_dfs,\n",
    "        test_hybrid_dfs,\n",
    "        feature_cols,\n",
    "        residual_target_cols,\n",
    "        feature_scaler,\n",
    "        residual_scaler,\n",
    "        seq_len=config.seq_len,\n",
    "        train_stride=config.train_stride,\n",
    "        eval_stride=config.eval_stride,\n",
    "    )\n",
    "\n",
    "    hy_train_groups = extract_window_groups(hy_train_ds)\n",
    "    hy_val_groups = extract_window_groups(hy_val_ds)\n",
    "    hy_test_groups = extract_window_groups(hy_test_ds)\n",
    "\n",
    "    hy_train_loader = DataLoader(\n",
    "        hy_train_ds,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    hy_val_loader = DataLoader(\n",
    "        hy_val_ds,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    hy_test_loader = DataLoader(\n",
    "        hy_test_ds,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    print(f\"Residual windows: train={len(hy_train_ds):,} val={len(hy_val_ds):,} test={len(hy_test_ds):,}\")\n",
    "\n",
    "    print(\"\\n[4/5] Training residual model and fusing with physics ...\")\n",
    "    hybrid_model_name = str(getattr(config, \"hybrid_model_name\", \"tcn\")).lower().strip()\n",
    "    if hybrid_model_name not in {\"tcn\", \"patchtst\", \"itransformer\"}:\n",
    "        raise ValueError(f\"Unsupported hybrid_model_name={hybrid_model_name}\")\n",
    "\n",
    "    res_model = make_model(hybrid_model_name).to(device)\n",
    "    res_optimizer = torch.optim.AdamW(\n",
    "        res_model.parameters(),\n",
    "        lr=float(get_model_lr(hybrid_model_name)),\n",
    "        weight_decay=float(config.weight_decay),\n",
    "    )\n",
    "    res_scheduler, res_warmup_epochs, res_warmup_lr_fn = _prepare_scheduler(\n",
    "        res_optimizer,\n",
    "        float(get_model_lr(hybrid_model_name)),\n",
    "    )\n",
    "    res_loss_fn = make_loss(config.loss_type)\n",
    "\n",
    "    res_best_ckpt = config.artifacts_dir / \"_tmp_best_states\" / f\"hybrid_residual_{hybrid_model_name}_best.pt\"\n",
    "    res_stopper = DualMetricEarlyStopping(\n",
    "        patience=int(getattr(config, \"hybrid_patience\", 12)),\n",
    "        min_epochs=max(8, int(getattr(config, \"hybrid_patience\", 12))),\n",
    "        delta_primary=1e-4,\n",
    "        delta_loss=float(config.delta_loss),\n",
    "        checkpoint_path=res_best_ckpt,\n",
    "    )\n",
    "\n",
    "    hybrid_history = {\n",
    "        \"train_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_r2_residual\": [],\n",
    "        \"lr_used\": [],\n",
    "    }\n",
    "\n",
    "    n_hybrid_epochs = int(getattr(config, \"hybrid_epochs\", 60))\n",
    "    for epoch in range(1, n_hybrid_epochs + 1):\n",
    "        lr_used = float(res_optimizer.param_groups[0][\"lr\"])\n",
    "        res_model.train()\n",
    "        tot_loss = 0.0\n",
    "        n_batches = 0\n",
    "\n",
    "        for x, y in tqdm(hy_train_loader, desc=f\"Hybrid-{hybrid_model_name} Epoch {epoch:3d}/{n_hybrid_epochs}\", leave=False):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y = torch.clamp(y, -10.0, 10.0)\n",
    "\n",
    "            res_optimizer.zero_grad(set_to_none=True)\n",
    "            pred = res_model(x)\n",
    "            loss = res_loss_fn(pred, y)\n",
    "            loss.backward()\n",
    "\n",
    "            _, has_nan, has_inf = check_gradients(res_model)\n",
    "            if has_nan or has_inf:\n",
    "                res_optimizer.zero_grad(set_to_none=True)\n",
    "                continue\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(res_model.parameters(), float(config.gradient_clip))\n",
    "            res_optimizer.step()\n",
    "            tot_loss += float(loss.item())\n",
    "            n_batches += 1\n",
    "\n",
    "        train_loss = tot_loss / max(1, n_batches)\n",
    "\n",
    "        val_loss, val_pred_res_sc, val_tgt_res_sc = evaluate(\n",
    "            res_model,\n",
    "            hy_val_loader,\n",
    "            device,\n",
    "            res_loss_fn,\n",
    "            desc=f\"Hybrid-Val {epoch:3d}\",\n",
    "            pred_clip=config.eval_pred_clip,\n",
    "        )\n",
    "        val_pred_res = residual_scaler.inverse_transform(val_pred_res_sc)\n",
    "        val_tgt_res = residual_scaler.inverse_transform(val_tgt_res_sc)\n",
    "\n",
    "        val_res_metrics = compute_metrics(\n",
    "            val_tgt_res,\n",
    "            val_pred_res,\n",
    "            target_names=residual_target_cols,\n",
    "            nan_eps=config.nan_eps,\n",
    "            scaled_pair=(val_tgt_res_sc, val_pred_res_sc),\n",
    "        )\n",
    "        val_primary = float(val_res_metrics.get(\"r2_vw_orig\", np.nan))\n",
    "\n",
    "        hybrid_history[\"train_loss\"].append(float(train_loss))\n",
    "        hybrid_history[\"val_loss\"].append(float(val_loss))\n",
    "        hybrid_history[\"val_r2_residual\"].append(float(val_primary) if np.isfinite(val_primary) else np.nan)\n",
    "        hybrid_history[\"lr_used\"].append(float(lr_used))\n",
    "\n",
    "        res_scheduler, _ = _step_scheduler(\n",
    "            epoch,\n",
    "            res_optimizer,\n",
    "            res_scheduler,\n",
    "            res_warmup_epochs,\n",
    "            res_warmup_lr_fn,\n",
    "            base_lr=float(get_model_lr(hybrid_model_name)),\n",
    "        )\n",
    "\n",
    "        should_stop = res_stopper.step(\n",
    "            primary_score=val_primary,\n",
    "            loss_value=float(val_loss),\n",
    "            model=res_model,\n",
    "            epoch=epoch,\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"[Hybrid-{hybrid_model_name}] Epoch {epoch:3d}/{n_hybrid_epochs} | \"\n",
    "            f\"train_loss={train_loss:.5f} | val_loss={val_loss:.5f} | residual_R2={val_primary:.5f}\"\n",
    "        )\n",
    "\n",
    "        if should_stop:\n",
    "            print(f\"[Hybrid-{hybrid_model_name}] Early stopping at epoch {epoch} (best_epoch={res_stopper.best_epoch})\")\n",
    "            break\n",
    "\n",
    "    # Restore best residual checkpoint.\n",
    "    if res_stopper.best_state is not None:\n",
    "        res_model.load_state_dict(res_stopper.best_state)\n",
    "        res_state_source = \"memory\"\n",
    "    elif res_stopper.best_state_path is not None and Path(res_stopper.best_state_path).exists():\n",
    "        res_model.load_state_dict(_load_checkpoint_state(Path(res_stopper.best_state_path)))\n",
    "        res_state_source = \"disk\"\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            f\"Hybrid residual model has no restorable checkpoint. last_checkpoint_error={res_stopper.last_checkpoint_error}\"\n",
    "        )\n",
    "    print(f\"Hybrid residual best checkpoint restored from {res_state_source}, best_epoch={res_stopper.best_epoch}\")\n",
    "\n",
    "    # Residual predictions on test windows.\n",
    "    hy_test_loss, hy_res_pred_sc, hy_res_tgt_sc = evaluate(\n",
    "        res_model,\n",
    "        hy_test_loader,\n",
    "        device,\n",
    "        res_loss_fn,\n",
    "        desc=\"Hybrid-TestResidual\",\n",
    "        pred_clip=config.eval_pred_clip,\n",
    "    )\n",
    "    hy_res_pred = residual_scaler.inverse_transform(hy_res_pred_sc)\n",
    "    hy_res_tgt = residual_scaler.inverse_transform(hy_res_tgt_sc)\n",
    "\n",
    "    # Align physics endpoints to residual-test windowing.\n",
    "    y_phys_resid, g_resid_from_phys, _ = extract_endpoint_values(\n",
    "        test_hybrid_dfs,\n",
    "        value_cols=physics_cols,\n",
    "        dropna_cols=feature_cols + residual_target_cols,\n",
    "        seq_len=config.seq_len,\n",
    "        stride=config.eval_stride,\n",
    "    )\n",
    "    y_true_resid_windows, g_resid_true, _ = extract_endpoint_values(\n",
    "        test_hybrid_dfs,\n",
    "        value_cols=target_cols,\n",
    "        dropna_cols=feature_cols + residual_target_cols,\n",
    "        seq_len=config.seq_len,\n",
    "        stride=config.eval_stride,\n",
    "    )\n",
    "    y_resid_true_ref, _, _ = extract_endpoint_values(\n",
    "        test_hybrid_dfs,\n",
    "        value_cols=residual_target_cols,\n",
    "        dropna_cols=feature_cols + residual_target_cols,\n",
    "        seq_len=config.seq_len,\n",
    "        stride=config.eval_stride,\n",
    "    )\n",
    "\n",
    "    n_aligned = min(len(hy_res_pred), len(hy_res_tgt), len(y_phys_resid), len(y_true_resid_windows), len(y_resid_true_ref))\n",
    "    hy_res_pred = hy_res_pred[:n_aligned]\n",
    "    hy_res_tgt = hy_res_tgt[:n_aligned]\n",
    "    y_phys_resid = y_phys_resid[:n_aligned]\n",
    "    y_true_resid_windows = y_true_resid_windows[:n_aligned]\n",
    "    y_resid_true_ref = y_resid_true_ref[:n_aligned]\n",
    "    hy_groups = g_resid_true[:n_aligned] if len(g_resid_true) >= n_aligned else np.arange(n_aligned, dtype=np.int32)\n",
    "\n",
    "    resid_align_mae = float(np.nanmean(np.abs(hy_res_tgt - y_resid_true_ref))) if n_aligned > 0 else np.nan\n",
    "    print(f\"Residual target alignment MAE (loader vs endpoint extraction): {resid_align_mae:.6e}\")\n",
    "\n",
    "    y_hybrid_pred = y_phys_resid + hy_res_pred\n",
    "    y_hybrid_true = y_true_resid_windows\n",
    "\n",
    "    hybrid_metrics = compute_metrics(\n",
    "        y_hybrid_true,\n",
    "        y_hybrid_pred,\n",
    "        target_names=target_cols,\n",
    "        nan_eps=config.nan_eps,\n",
    "        scaled_pair=None,\n",
    "    )\n",
    "    hybrid_traj_metrics = compute_trajectory_weighted_metrics(\n",
    "        y_hybrid_true,\n",
    "        y_hybrid_pred,\n",
    "        window_groups=hy_groups,\n",
    "        target_names=target_cols,\n",
    "        nan_eps=config.nan_eps,\n",
    "        scaled_pair=None,\n",
    "        target_scale=target_scale_iqr_orig,\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Hybrid global_R2_vw_orig={hybrid_metrics['r2_vw_orig']:.4f}  \"\n",
    "        f\"RMSE={hybrid_metrics['rmse']:.4f}  MAE={hybrid_metrics['mae']:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Deep champion predictions (for visual parity and time-series figures).\n",
    "    champ_loss_fn = make_loss(config.loss_type)\n",
    "    _, deep_pred_sc, deep_tgt_sc = evaluate(\n",
    "        champion_model,\n",
    "        test_loader,\n",
    "        device,\n",
    "        champ_loss_fn,\n",
    "        desc=f\"Test-{champion_model_name}-for-figs\",\n",
    "        pred_clip=config.eval_pred_clip,\n",
    "    )\n",
    "    deep_pred_orig = target_scaler.inverse_transform(deep_pred_sc)\n",
    "    deep_tgt_orig = target_scaler.inverse_transform(deep_tgt_sc)\n",
    "\n",
    "    # Best XGBoost baseline already computed in et_benchmark_results.\n",
    "    best_xgb_name = None\n",
    "    best_xgb_metrics = None\n",
    "    if isinstance(et_benchmark_results, dict) and len(et_benchmark_results) > 0:\n",
    "        best_score = -np.inf\n",
    "        for name, payload in et_benchmark_results.items():\n",
    "            if payload.get(\"status\") != \"ok\":\n",
    "                continue\n",
    "            met = payload.get(\"metrics\", {})\n",
    "            score = float(met.get(\"r2_vw_orig\", np.nan))\n",
    "            if np.isfinite(score) and score > best_score:\n",
    "                best_score = score\n",
    "                best_xgb_name = name\n",
    "                best_xgb_metrics = met\n",
    "\n",
    "    print(\"\\n[5/5] Building paper-quality figures ...\")\n",
    "    fig_dir = config.artifacts_dir / \"paper_figures\"\n",
    "    fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Model comparison rows (global metrics)\n",
    "    comparison_rows_extended = []\n",
    "    comparison_rows_extended.append({\n",
    "        \"model\": f\"Deep-{champion_model_name}\",\n",
    "        \"metrics\": test_metrics,\n",
    "    })\n",
    "    if best_xgb_metrics is not None:\n",
    "        comparison_rows_extended.append({\n",
    "            \"model\": f\"XGBoost-{best_xgb_name}\",\n",
    "            \"metrics\": best_xgb_metrics,\n",
    "        })\n",
    "    comparison_rows_extended.append({\n",
    "        \"model\": \"PhysicsProxy\",\n",
    "        \"metrics\": physics_metrics,\n",
    "    })\n",
    "    comparison_rows_extended.append({\n",
    "        \"model\": f\"Hybrid-{hybrid_model_name}\",\n",
    "        \"metrics\": hybrid_metrics,\n",
    "    })\n",
    "\n",
    "    # Figure 1: Global metric bars.\n",
    "    fig1, axes = plt.subplots(1, 3, figsize=(16, 4.6), dpi=180)\n",
    "    model_names = [r[\"model\"] for r in comparison_rows_extended]\n",
    "    r2_vals = [float(r[\"metrics\"].get(\"r2_vw_orig\", np.nan)) for r in comparison_rows_extended]\n",
    "    rmse_vals = [float(r[\"metrics\"].get(\"rmse\", np.nan)) for r in comparison_rows_extended]\n",
    "    mae_vals = [float(r[\"metrics\"].get(\"mae\", np.nan)) for r in comparison_rows_extended]\n",
    "\n",
    "    palettes = [\"#2a9d8f\", \"#457b9d\", \"#6c757d\", \"#e76f51\", \"#264653\"]\n",
    "    colors = palettes[:len(model_names)]\n",
    "\n",
    "    axes[0].bar(model_names, r2_vals, color=colors)\n",
    "    axes[0].axhline(0.0, color=\"black\", linewidth=0.8)\n",
    "    axes[0].set_title(\"Global R2 (Variance-Weighted)\")\n",
    "    axes[0].set_ylabel(\"R2\")\n",
    "    axes[0].tick_params(axis=\"x\", rotation=20)\n",
    "\n",
    "    axes[1].bar(model_names, rmse_vals, color=colors)\n",
    "    axes[1].set_title(\"Global RMSE\")\n",
    "    axes[1].set_ylabel(\"RMSE\")\n",
    "    axes[1].tick_params(axis=\"x\", rotation=20)\n",
    "\n",
    "    axes[2].bar(model_names, mae_vals, color=colors)\n",
    "    axes[2].set_title(\"Global MAE\")\n",
    "    axes[2].set_ylabel(\"MAE\")\n",
    "    axes[2].tick_params(axis=\"x\", rotation=20)\n",
    "\n",
    "    fig1.suptitle(\"Model Comparison on Unseen Trajectories\", fontsize=13)\n",
    "    fig1.tight_layout()\n",
    "    fig1_png = fig_dir / \"fig1_global_model_comparison.png\"\n",
    "    fig1_pdf = fig_dir / \"fig1_global_model_comparison.pdf\"\n",
    "    fig1.savefig(fig1_png, bbox_inches=\"tight\")\n",
    "    fig1.savefig(fig1_pdf, bbox_inches=\"tight\")\n",
    "    plt.close(fig1)\n",
    "\n",
    "    # Figure 2: Per-target R2 heatmap.\n",
    "    target_short = []\n",
    "    for t in target_cols:\n",
    "        t_low = str(t).lower()\n",
    "        if t_low == \"ft_1_eff\":\n",
    "            target_short.append(\"Fx\")\n",
    "        elif t_low == \"ft_2_eff\":\n",
    "            target_short.append(\"Fy\")\n",
    "        elif t_low == \"ft_3_eff\":\n",
    "            target_short.append(\"Fz\")\n",
    "        elif t_low == \"ft_4_eff\":\n",
    "            target_short.append(\"Tx\")\n",
    "        elif t_low == \"ft_5_eff\":\n",
    "            target_short.append(\"Ty\")\n",
    "        elif t_low == \"ft_6_eff\":\n",
    "            target_short.append(\"Tz\")\n",
    "        else:\n",
    "            target_short.append(str(t))\n",
    "\n",
    "    r2_mat = np.asarray(\n",
    "        [np.asarray(r[\"metrics\"].get(\"r2_per_target\", [np.nan] * len(target_cols)), dtype=np.float64) for r in comparison_rows_extended],\n",
    "        dtype=np.float64,\n",
    "    )\n",
    "\n",
    "    fig2, ax2 = plt.subplots(figsize=(10.5, 4.8), dpi=180)\n",
    "    im = ax2.imshow(r2_mat, aspect=\"auto\", cmap=\"RdYlGn\", vmin=-0.2, vmax=1.0)\n",
    "    ax2.set_xticks(np.arange(len(target_short)))\n",
    "    ax2.set_xticklabels(target_short)\n",
    "    ax2.set_yticks(np.arange(len(model_names)))\n",
    "    ax2.set_yticklabels(model_names)\n",
    "    ax2.set_title(\"Per-Target R2 Heatmap\")\n",
    "\n",
    "    for i in range(r2_mat.shape[0]):\n",
    "        for j in range(r2_mat.shape[1]):\n",
    "            val = r2_mat[i, j]\n",
    "            txt = \"nan\" if not np.isfinite(val) else f\"{val:.2f}\"\n",
    "            ax2.text(j, i, txt, ha=\"center\", va=\"center\", fontsize=8, color=\"black\")\n",
    "\n",
    "    cbar = fig2.colorbar(im, ax=ax2, fraction=0.03, pad=0.02)\n",
    "    cbar.set_label(\"R2\")\n",
    "    fig2.tight_layout()\n",
    "    fig2_png = fig_dir / \"fig2_per_target_r2_heatmap.png\"\n",
    "    fig2_pdf = fig_dir / \"fig2_per_target_r2_heatmap.pdf\"\n",
    "    fig2.savefig(fig2_png, bbox_inches=\"tight\")\n",
    "    fig2.savefig(fig2_pdf, bbox_inches=\"tight\")\n",
    "    plt.close(fig2)\n",
    "\n",
    "    # Figure 3: Parity plots (flattened over targets).\n",
    "    def _sample_flat_pairs(y_true, y_pred, max_points=8000, seed=42):\n",
    "        yt = np.asarray(y_true, dtype=np.float64).reshape(-1)\n",
    "        yp = np.asarray(y_pred, dtype=np.float64).reshape(-1)\n",
    "        n = min(len(yt), len(yp))\n",
    "        yt = yt[:n]\n",
    "        yp = yp[:n]\n",
    "        mask = np.isfinite(yt) & np.isfinite(yp)\n",
    "        yt = yt[mask]\n",
    "        yp = yp[mask]\n",
    "        if len(yt) > max_points:\n",
    "            rng = np.random.RandomState(seed)\n",
    "            idx = rng.choice(len(yt), size=max_points, replace=False)\n",
    "            yt = yt[idx]\n",
    "            yp = yp[idx]\n",
    "        return yt, yp\n",
    "\n",
    "    parity_models = [\n",
    "        (\"Deep\", deep_tgt_orig, deep_pred_orig),\n",
    "        (\"Physics\", y_true_phys, y_phys_pred),\n",
    "        (\"Hybrid\", y_hybrid_true, y_hybrid_pred),\n",
    "    ]\n",
    "\n",
    "    fig3, axes3 = plt.subplots(1, 3, figsize=(15.5, 4.6), dpi=180)\n",
    "    for ax, (name, yt, yp) in zip(axes3, parity_models):\n",
    "        yt_s, yp_s = _sample_flat_pairs(yt, yp, max_points=int(getattr(config, \"hybrid_plot_max_points\", 8000)))\n",
    "        if len(yt_s) == 0:\n",
    "            ax.text(0.5, 0.5, \"No data\", ha=\"center\", va=\"center\", transform=ax.transAxes)\n",
    "            ax.set_title(f\"{name} Parity\")\n",
    "            continue\n",
    "        ax.scatter(yt_s, yp_s, s=6, alpha=0.35, color=\"#1d3557\", edgecolors=\"none\")\n",
    "        lo = np.nanpercentile(np.concatenate([yt_s, yp_s]), 1.0)\n",
    "        hi = np.nanpercentile(np.concatenate([yt_s, yp_s]), 99.0)\n",
    "        ax.plot([lo, hi], [lo, hi], \"--\", color=\"#e63946\", linewidth=1.4)\n",
    "        ax.set_title(f\"{name} Parity\")\n",
    "        ax.set_xlabel(\"Actual\")\n",
    "        ax.set_ylabel(\"Predicted\")\n",
    "        ax.grid(alpha=0.25)\n",
    "\n",
    "    fig3.suptitle(\"Parity Diagnostics (All Targets Flattened)\", fontsize=13)\n",
    "    fig3.tight_layout()\n",
    "    fig3_png = fig_dir / \"fig3_parity_plots.png\"\n",
    "    fig3_pdf = fig_dir / \"fig3_parity_plots.pdf\"\n",
    "    fig3.savefig(fig3_png, bbox_inches=\"tight\")\n",
    "    fig3.savefig(fig3_pdf, bbox_inches=\"tight\")\n",
    "    plt.close(fig3)\n",
    "\n",
    "    # Figure 4: Time-series overlay for first test trajectory (if available).\n",
    "    n_common = min(len(deep_tgt_orig), len(deep_pred_orig), len(y_phys_pred), len(y_hybrid_pred), len(test_window_groups))\n",
    "    deep_tgt_use = deep_tgt_orig[:n_common]\n",
    "    deep_pred_use = deep_pred_orig[:n_common]\n",
    "    phys_use = y_phys_pred[:n_common]\n",
    "    hybrid_use = y_hybrid_pred[:n_common]\n",
    "    groups_use = np.asarray(test_window_groups[:n_common], dtype=np.int32)\n",
    "\n",
    "    fig4, axes4 = plt.subplots(2, 3, figsize=(17, 7), dpi=180, sharex=True)\n",
    "    unique_groups = np.unique(groups_use)\n",
    "    if unique_groups.size > 0:\n",
    "        gid = int(unique_groups[0])\n",
    "        idx = np.flatnonzero(groups_use == gid)\n",
    "    else:\n",
    "        idx = np.arange(min(500, n_common), dtype=np.int64)\n",
    "\n",
    "    if idx.size == 0:\n",
    "        idx = np.arange(min(500, n_common), dtype=np.int64)\n",
    "\n",
    "    for j, ax in enumerate(axes4.flatten()):\n",
    "        if j >= len(target_cols):\n",
    "            ax.axis(\"off\")\n",
    "            continue\n",
    "        ax.plot(idx, deep_tgt_use[idx, j], color=\"black\", linewidth=1.8, label=\"Actual\")\n",
    "        ax.plot(idx, deep_pred_use[idx, j], color=\"#457b9d\", linewidth=1.3, label=f\"Deep-{champion_model_name}\")\n",
    "        ax.plot(idx, phys_use[idx, j], color=\"#6c757d\", linewidth=1.1, linestyle=\"--\", label=\"Physics\")\n",
    "        ax.plot(idx, hybrid_use[idx, j], color=\"#e76f51\", linewidth=1.3, label=f\"Hybrid-{hybrid_model_name}\")\n",
    "        ax.set_title(target_short[j])\n",
    "        ax.grid(alpha=0.25)\n",
    "\n",
    "    handles, labels = axes4[0, 0].get_legend_handles_labels()\n",
    "    fig4.legend(handles, labels, loc=\"upper center\", ncol=4, frameon=False)\n",
    "    fig4.suptitle(\"Trajectory Overlay: Actual vs Deep vs Physics vs Hybrid\", fontsize=13)\n",
    "    fig4.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig4_png = fig_dir / \"fig4_timeseries_overlay.png\"\n",
    "    fig4_pdf = fig_dir / \"fig4_timeseries_overlay.pdf\"\n",
    "    fig4.savefig(fig4_png, bbox_inches=\"tight\")\n",
    "    fig4.savefig(fig4_pdf, bbox_inches=\"tight\")\n",
    "    plt.close(fig4)\n",
    "\n",
    "    paper_figure_paths = {\n",
    "        \"fig1_global_model_comparison_png\": str(fig1_png),\n",
    "        \"fig1_global_model_comparison_pdf\": str(fig1_pdf),\n",
    "        \"fig2_per_target_r2_heatmap_png\": str(fig2_png),\n",
    "        \"fig2_per_target_r2_heatmap_pdf\": str(fig2_pdf),\n",
    "        \"fig3_parity_plots_png\": str(fig3_png),\n",
    "        \"fig3_parity_plots_pdf\": str(fig3_pdf),\n",
    "        \"fig4_timeseries_overlay_png\": str(fig4_png),\n",
    "        \"fig4_timeseries_overlay_pdf\": str(fig4_pdf),\n",
    "    }\n",
    "\n",
    "    hybrid_results = {\n",
    "        \"hybrid_model_name\": hybrid_model_name,\n",
    "        \"physics_model\": {\n",
    "            \"type\": \"ridge_physics_proxy\",\n",
    "            \"alpha\": float(getattr(config, \"physics_alpha\", 2.0)),\n",
    "            \"n_train_rows\": int(len(X_phys_train)),\n",
    "            \"n_features\": int(X_phys_train.shape[1]),\n",
    "            \"metrics\": physics_metrics,\n",
    "            \"traj_metrics\": physics_traj_metrics,\n",
    "        },\n",
    "        \"residual_model\": {\n",
    "            \"name\": hybrid_model_name,\n",
    "            \"test_loss\": float(hy_test_loss),\n",
    "            \"best_epoch\": int(res_stopper.best_epoch),\n",
    "            \"best_primary_score\": float(res_stopper.best_primary_score) if np.isfinite(res_stopper.best_primary_score) else np.nan,\n",
    "            \"best_state_source\": res_state_source,\n",
    "            \"checkpoint_path\": str(res_stopper.best_state_path) if res_stopper.best_state_path is not None else None,\n",
    "            \"history\": hybrid_history,\n",
    "            \"residual_metrics\": compute_metrics(\n",
    "                hy_res_tgt,\n",
    "                hy_res_pred,\n",
    "                target_names=residual_target_cols,\n",
    "                nan_eps=config.nan_eps,\n",
    "                scaled_pair=None,\n",
    "            ),\n",
    "        },\n",
    "        \"hybrid_fused\": {\n",
    "            \"metrics\": hybrid_metrics,\n",
    "            \"traj_metrics\": hybrid_traj_metrics,\n",
    "        },\n",
    "        \"alignment\": {\n",
    "            \"n_windows_aligned\": int(n_aligned),\n",
    "            \"residual_target_alignment_mae\": float(resid_align_mae),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    print(\"\\nHybrid summary:\")\n",
    "    print(f\"  Physics-only R2: {physics_metrics['r2_vw_orig']:.4f}\")\n",
    "    print(f\"  Hybrid fused R2: {hybrid_metrics['r2_vw_orig']:.4f}\")\n",
    "    if best_xgb_metrics is not None:\n",
    "        print(f\"  Best XGBoost ({best_xgb_name}) R2: {best_xgb_metrics.get('r2_vw_orig', np.nan):.4f}\")\n",
    "    print(f\"  Deep champion ({champion_model_name}) R2: {test_metrics['r2_vw_orig']:.4f}\")\n",
    "\n",
    "    print(\"\\nSaved paper-style figures:\")\n",
    "    for k, v in paper_figure_paths.items():\n",
    "        print(f\"  {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2903ad2",
   "metadata": {},
   "source": [
    "## 13. Save Results to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445b5733",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "config.artifacts_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def _jsonable(obj):\n",
    "    if isinstance(obj, Path):\n",
    "        return str(obj)\n",
    "    if isinstance(obj, dict):\n",
    "        return {str(k): _jsonable(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return [_jsonable(v) for v in obj]\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    if isinstance(obj, (np.floating,)):\n",
    "        v = float(obj)\n",
    "        return v if np.isfinite(v) else None\n",
    "    if isinstance(obj, (np.integer,)):\n",
    "        return int(obj)\n",
    "    if isinstance(obj, (np.bool_,)):\n",
    "        return bool(obj)\n",
    "    if isinstance(obj, float):\n",
    "        return obj if np.isfinite(obj) else None\n",
    "    return obj\n",
    "\n",
    "\n",
    "# Save all successful deep models\n",
    "deep_checkpoints = {}\n",
    "for model_name, model_obj in trained_models.items():\n",
    "    model_path = config.artifacts_dir / f\"{model_name}_best.pt\"\n",
    "    torch.save(\n",
    "        {\n",
    "            \"model_state_dict\": model_obj.state_dict(),\n",
    "            \"model_name\": model_name,\n",
    "            \"config\": _jsonable(asdict(config)),\n",
    "            \"feature_cols\": feature_cols,\n",
    "            \"target_cols\": target_cols,\n",
    "            \"training_summary\": deep_training_results.get(model_name, {}),\n",
    "            \"test_metrics\": deep_test_results.get(model_name, {}).get(\"metrics\", {}),\n",
    "            \"test_traj_metrics\": deep_test_results.get(model_name, {}).get(\"traj_metrics\", {}),\n",
    "        },\n",
    "        model_path,\n",
    "    )\n",
    "    deep_checkpoints[model_name] = str(model_path)\n",
    "    print(f\"Saved checkpoint: {model_path}\")\n",
    "\n",
    "benchmark_results = {\n",
    "    \"timestamp_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "    \"device\": str(device),\n",
    "    \"seed\": int(config.seed),\n",
    "    \"config\": _jsonable(asdict(config)),\n",
    "    \"selection\": {\n",
    "        \"primary_metric\": config.primary_metric,\n",
    "        \"secondary_metric\": config.secondary_metric,\n",
    "    },\n",
    "    \"feature_cols\": list(feature_cols),\n",
    "    \"target_cols\": list(target_cols),\n",
    "    \"data_summary\": {\n",
    "        \"train_trajectories\": int(len(train_files)),\n",
    "        \"val_trajectories\": int(len(val_files)),\n",
    "        \"test_trajectories\": int(len(test_files)),\n",
    "        \"train_windows\": int(len(train_ds)),\n",
    "        \"val_windows\": int(len(val_ds)),\n",
    "        \"test_windows\": int(len(test_ds)),\n",
    "    },\n",
    "    \"deep_training_results\": _jsonable(deep_training_results),\n",
    "    \"deep_test_results\": _jsonable(deep_test_results),\n",
    "    \"deep_leaderboard\": _jsonable(leaderboard_rows),\n",
    "    \"champion_model_name\": champion_model_name,\n",
    "    \"champion_metrics\": _jsonable(test_metrics),\n",
    "    \"champion_traj_metrics\": _jsonable(test_traj_metrics),\n",
    "    \"xgboost_results\": _jsonable(et_benchmark_results),\n",
    "    \"extratrees_results\": _jsonable(et_benchmark_results),  # backward compatibility\n",
    "    \"hybrid_results\": _jsonable(hybrid_results) if \"hybrid_results\" in globals() else None,\n",
    "    \"hybrid_comparison_rows\": _jsonable(comparison_rows_extended) if \"comparison_rows_extended\" in globals() else None,\n",
    "    \"paper_figure_paths\": _jsonable(paper_figure_paths) if \"paper_figure_paths\" in globals() else None,\n",
    "    \"deep_checkpoints\": deep_checkpoints,\n",
    "    \"total_train_time_seconds\": float(total_train_time),\n",
    "}\n",
    "\n",
    "results_path = config.artifacts_dir / \"benchmark_results_full.json\"\n",
    "with open(results_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(benchmark_results, f, indent=2)\n",
    "print(f\"Saved benchmark JSON: {results_path}\")\n",
    "\n",
    "history_path = config.artifacts_dir / \"deep_histories.json\"\n",
    "with open(history_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(_jsonable(deep_histories), f, indent=2)\n",
    "print(f\"Saved deep histories: {history_path}\")\n",
    "\n",
    "if et_memmap_dirs:\n",
    "    print(\"\\nCleaning temporary baseline memmap dirs...\")\n",
    "    for mm_dir in et_memmap_dirs:\n",
    "        try:\n",
    "            for p in mm_dir.glob(\"*\"):\n",
    "                try:\n",
    "                    p.unlink()\n",
    "                except Exception:\n",
    "                    pass\n",
    "            mm_dir.rmdir()\n",
    "            print(f\"  removed {mm_dir}\")\n",
    "        except Exception as exc:\n",
    "            print(f\"  warning: failed to cleanup {mm_dir}: {exc}\")\n",
    "\n",
    "print(\"\\nDone.\")\n",
    "print(f\"Artifacts location: {config.artifacts_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842497ad",
   "metadata": {},
   "source": [
    "## 14. Summary of Improvements\n",
    "\n",
    "**ðŸŽ¯ What Was Fixed:**\n",
    "\n",
    "1. **Per-Target Normalization** - Each F/T component scaled independently\n",
    "2. **Stronger Gradient Clipping** - 1.0 â†’ 5.0 (prevents explosions)\n",
    "3. **Lower Learning Rate** - 1e-3 â†’ 5e-4 with 5-epoch warmup\n",
    "4. **Gradient Monitoring** - Auto-detects and skips NaN/Inf batches\n",
    "5. **Prediction Clipping** - Prevents extreme values during training\n",
    "6. **Better Hyperparameters** - Smaller batches (256), higher dropout (0.3)\n",
    "7. **MSE Loss** - More stable than Huber for initial training\n",
    "\n",
    "**ðŸ“Š Expected vs Previous Results:**\n",
    "\n",
    "| Metric | Previous | Expected | Improvement |\n",
    "|--------|----------|----------|-------------|\n",
    "| Overall RÂ² | 0.2483 | 0.50-0.65 | +100-160% |\n",
    "| ft_1_eff RÂ² | -0.14 | +0.40+ | âœ“ Fixed |\n",
    "| ft_4_eff RÂ² | -0.64 | +0.35+ | âœ“ Fixed |\n",
    "| Val Stability | Huge swings | Smooth | âœ“ Fixed |\n",
    "| Max Gradient | Unknown | <5.0 | âœ“ Monitored |\n",
    "\n",
    "All targets should now achieve **positive RÂ² scores**! ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
